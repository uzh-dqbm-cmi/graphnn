{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "from tqdm import tqdm\n",
    "import hiplot as hip\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/home/skyriakos/chemprop_run/git/notebooks\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.run_workflow import *\n",
    "from deepadr.chemfeatures import *\n",
    "from deepadr.hyphelper import *\n",
    "# from deepadr.model_gnn import GCN as testGCN\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf, ExpressionNN\n",
    "# from deepadr.model_attn_siamese import *\n",
    "from ogb.graphproppred import Evaluator\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tdc.single_pred import Tox\n",
    "# from tdc.multi_pred import DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 8\n",
      "cuda:0, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:1, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:2, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:3, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:4, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:5, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:6, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:7, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "# device_gpu = get_device(True, index=0)\n",
    "\n",
    "# fdtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.9.1\n",
      "CUDA: 11.1\n",
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:03) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary(device=device_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDC Tox\n",
    "DSdataset_name = 'SynergxZloewe' #'OncoPolyPharmacology' #'DrugComb'\n",
    "\n",
    "#fname_suffix = ds_config[\"fname_suffix\"]\n",
    "similarity_types = ['chem']\n",
    "kernel_option = 'sqeuclidean'\n",
    "data_fname = 'data_v1'\n",
    "# interact_matfname = ds_config[\"interact_matfname\"]\n",
    "# exp_iden = 'simtypeall'\n",
    "# ddi_interaction_labels_pth = ds_config[\"ddi_interaction_labels_pth\"]\n",
    "\n",
    "# up_dir, processed_dir, DSdataset_name, data_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "/cluster/home/skyriakos/chemprop_run/git/data/processed/SynergxZloewe/data_v1\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "targetdata_dir_raw = create_directory(os.path.join(targetdata_dir, \"raw\"))\n",
    "targetdata_dir_processed = create_directory(os.path.join(targetdata_dir, \"processed\"))\n",
    "# # ReaderWriter.dump_data(dpartitions, os.path.join(targetdata_dir, 'data_partitions.pkl'))\n",
    "print(targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 424 ms, total: 424 ms\n",
      "Wall time: 425 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make sure to first run the \"data_generation\" notebook first\n",
    "\n",
    "dataset = MoleculeDataset(root=targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('====================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# # data0 = dataset[0]  # Get the first graph object.\n",
    "\n",
    "# # print()\n",
    "# # print(data)\n",
    "# # print('=============================================================')\n",
    "\n",
    "# # # Gather some statistics about the first graph.\n",
    "# # print(f'Number of nodes: {data.num_nodes}')\n",
    "# # print(f'Number of edges: {data.num_edges}')\n",
    "# # print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# # print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "# # print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "# # print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data0.expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data0.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_dataset = dataset\n",
    "\n",
    "# If you want to use a smaller subset of the dataset for testing\n",
    "smaller_dataset_len = int(len(dataset)/1)\n",
    "used_dataset = dataset[:smaller_dataset_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepadr.dataset.MoleculeDataset"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(used_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_num: 0\n",
      "train data\n",
      "class: 0 norm count: 0.4793293229233329\n",
      "class: 1 norm count: 0.5206706770766671\n",
      "validation data\n",
      "class: 0 norm count: 0.4793483626789534\n",
      "class: 1 norm count: 0.5206516373210466\n",
      "test data\n",
      "class: 0 norm count: 0.4793312269615587\n",
      "class: 1 norm count: 0.5206687730384413\n",
      "\n",
      "-------------------------\n",
      "fold_num: 1\n",
      "train data\n",
      "class: 0 norm count: 0.4793293229233329\n",
      "class: 1 norm count: 0.5206706770766671\n",
      "validation data\n",
      "class: 0 norm count: 0.4793483626789534\n",
      "class: 1 norm count: 0.5206516373210466\n",
      "test data\n",
      "class: 0 norm count: 0.4793312269615587\n",
      "class: 1 norm count: 0.5206687730384413\n",
      "\n",
      "-------------------------\n",
      "fold_num: 2\n",
      "train data\n",
      "class: 0 norm count: 0.4793293229233329\n",
      "class: 1 norm count: 0.5206706770766671\n",
      "validation data\n",
      "class: 0 norm count: 0.4793483626789534\n",
      "class: 1 norm count: 0.5206516373210466\n",
      "test data\n",
      "class: 0 norm count: 0.4793312269615587\n",
      "class: 1 norm count: 0.5206687730384413\n",
      "\n",
      "-------------------------\n",
      "fold_num: 3\n",
      "train data\n",
      "class: 0 norm count: 0.4793293229233329\n",
      "class: 1 norm count: 0.5206706770766671\n",
      "validation data\n",
      "class: 0 norm count: 0.4793483626789534\n",
      "class: 1 norm count: 0.5206516373210466\n",
      "test data\n",
      "class: 0 norm count: 0.4793312269615587\n",
      "class: 1 norm count: 0.5206687730384413\n",
      "\n",
      "-------------------------\n",
      "fold_num: 4\n",
      "train data\n",
      "class: 0 norm count: 0.4793293229233329\n",
      "class: 1 norm count: 0.5206706770766671\n",
      "validation data\n",
      "class: 0 norm count: 0.4793483626789534\n",
      "class: 1 norm count: 0.5206516373210466\n",
      "test data\n",
      "class: 0 norm count: 0.4793312269615587\n",
      "class: 1 norm count: 0.5206687730384413\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_partitions = get_stratified_partitions(used_dataset.data.y[:smaller_dataset_len],\n",
    "                                            num_folds=5, valid_set_portion=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_test_frac = [0.7, 0.1, 0.2]\n",
    "# assert sum(train_val_test_frac) == 1\n",
    "\n",
    "# torch.manual_seed(42)\n",
    "# used_dataset = used_dataset.shuffle()\n",
    "\n",
    "# num_train = round(train_val_test_frac[0] * len(used_dataset)) \n",
    "# num_trainval = round((train_val_test_frac[0]+train_val_test_frac[1]) * len(used_dataset))\n",
    "\n",
    "# train_dataset = used_dataset[:num_train]\n",
    "# val_dataset = used_dataset[num_train:num_trainval]\n",
    "# test_dataset = used_dataset[num_trainval:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Subset(used_dataset, fold_partitions[0]['train'])\n",
    "# val_dataset = Subset(used_dataset, fold_partitions[0]['validation'])\n",
    "# test_dataset = Subset(used_dataset, fold_partitions[0]['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Number of training graphs: {len(train_dataset)}')\n",
    "# print(f'Number of val graphs: {len(val_dataset)}')\n",
    "# print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 54691\n",
      "Number of training graphs: 6077\n",
      "Number of training graphs: 15192\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['train'])))\n",
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['validation'])))\n",
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['test'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "tp = {\n",
    "    \"batch_size\" : 300,\n",
    "    \"num_epochs\" : 50,\n",
    "    \n",
    "    \"emb_dim\" : 300,\n",
    "    \"gnn_type\" : \"gatv2\",\n",
    "    \"num_layer\" : 5,\n",
    "    \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "    \"input_embed_dim\" : None,\n",
    "    \"gene_embed_dim\": 1,\n",
    "    \"num_attn_heads\" : 2,\n",
    "    \"num_transformer_units\" : 1,\n",
    "    \"p_dropout\" : 0.3,\n",
    "#     \"nonlin_func\" : nn.ReLU(),\n",
    "    \"mlp_embed_factor\" : 2,\n",
    "    \"pooling_mode\" : 'attn',\n",
    "    \"dist_opt\" : 'cosine',\n",
    "\n",
    "    \"base_lr\" : 3e-5, #3e-4\n",
    "    \"max_lr_mul\": 5,\n",
    "    \"l2_reg\" : 1e-7,\n",
    "    \"loss_w\" : 0.1,\n",
    "    \"margin_v\" : 1.,\n",
    "\n",
    "    \"expression_dim\" : 64,\n",
    "    \"expression_input_size\" : 908,\n",
    "    \"exp_H1\" : 500,\n",
    "    \"exp_H2\" : 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_embed_dim = [128]\n",
    "num_attn_heads = [2] # 2,4\n",
    "num_transformer_units = [1]\n",
    "p_dropout = [0.3]\n",
    "# nonlin_func = [nn.ReLU()]\n",
    "# mlp_embed_factor = [2]\n",
    "# pooling_mode = ['attn']\n",
    "# dist_opt = ['cosine']\n",
    "l2_reg = [1e-7] #0\n",
    "batch_size = [300]\n",
    "# num_epochs = [200]\n",
    "loss_w = [0.1] # 0.05, \n",
    "base_lr = [3e-4, 3e-5]\n",
    "max_lr_mul = [3,5,10,15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_names = [\"num_attn_heads\",\n",
    "            \"p_dropout\",\n",
    "            \"l2_reg\",\n",
    "            \"loss_w\",\n",
    "           \"num_transformer_units\",\n",
    "           \"batch_size\",\n",
    "           \"base_lr\",\n",
    "           \"max_lr_mul\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [0.3], [1e-07], [0.1], [1], [300], [0.0003, 3e-05], [3, 5, 10, 15]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[globals()[i] for i in hp_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "hyperparam_space = list(itertools.product(*[globals()[i] for i in hp_names]))\n",
    "print(len(hyperparam_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.3, 1e-07, 0.1, 1, 300, 0.0003, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_space[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir_exp = create_directory(os.path.join(targetdata_dir, \"experiments\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_gpu = get_device(True, index=0)\n",
    "# exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp0\"))\n",
    "# tphp = generate_tp_hp(tp, hyperparam_space[0], hp_names)\n",
    "# partition = fold_partitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_exp(tphp, device_gpu, exp_dir,partition=fold_partitions[0], used_dataset=used_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(queue, used_dataset, gpu_num, tphp, exp_dir, partition): #\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelper.run_exp, args=(queue, used_dataset, gpu_num, tphp, exp_dir, partition)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2022-01-26_12-38-57\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:0\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:1\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:2\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:3\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:4\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:5\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:6\n",
      "<<< joined hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/skyriakos/chemprop_run/git/deepadr/hyphelper.py\", line 51, in run_exp\n",
      "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/opt/conda/envs/graphnn/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ReLU is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13052/1331147900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mjoin_q_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mreleased_gpu_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"released_gpu_num:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreleased_gpu_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawned_processes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "q_processes = []\n",
    "\n",
    "partition = fold_partitions[0]\n",
    "\n",
    "print(\"Start: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "\n",
    "for q_i in range(min(n_gpu, len(hyperparam_space))):\n",
    "#     device_gpu = get_device(True, index=q_i)\n",
    "    time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "    tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "    \n",
    "    q_process = create_q_process(queue, used_dataset, q_i, tphp, exp_dir, partition)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "for q_i in range(len(hyperparam_space)):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "    if(spawned_processes < len(hyperparam_space)):\n",
    "#         device_gpu = get_device(True, index=q_i)\n",
    "        time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "        tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "\n",
    "        q_process = create_q_process(queue, used_dataset, released_gpu_num, tphp, exp_dir, partition)\n",
    "        q_processes.append(q_process)\n",
    "        spawn_q_process(q_process)\n",
    "        spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "exp_dirs = glob.glob(targetdata_dir_exp+\"/exp_*\")\n",
    "len(exp_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results = []\n",
    "\n",
    "for edir in exp_dirs:\n",
    "    hp = pd.read_json(edir + \"/hyperparameters.json\", typ=\"Series\").to_dict()\n",
    "    hp['maxTestAUPR'] = pd.read_csv(edir + \"/curves.csv\").test.max()\n",
    "    exp_results.append(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip.Experiment.from_iterable(exp_results).display(force_full_width=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
