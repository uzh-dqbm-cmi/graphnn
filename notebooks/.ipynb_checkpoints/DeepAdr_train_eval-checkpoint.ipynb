{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/home/skyriakos/chemprop_run/git/notebooks\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.run_workflow import *\n",
    "from deepadr.chemfeatures import *\n",
    "# from deepadr.model_gnn import GCN as testGCN\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf\n",
    "# from deepadr.model_attn_siamese import *\n",
    "from ogb.graphproppred import Evaluator\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tdc.single_pred import Tox\n",
    "from tdc.multi_pred import DDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 1\n",
      "cuda:0, name:GeForce GTX 1080 Ti\n",
      "total memory available: 10.91650390625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDC Tox\n",
    "DSdataset_name = 'TWOSIDES' #'DrugBank'\n",
    "\n",
    "#fname_suffix = ds_config[\"fname_suffix\"]\n",
    "similarity_types = ['chem']\n",
    "kernel_option = 'sqeuclidean'\n",
    "data_fname = 'data_v1'\n",
    "# interact_matfname = ds_config[\"interact_matfname\"]\n",
    "# exp_iden = 'simtypeall'\n",
    "# ddi_interaction_labels_pth = ds_config[\"ddi_interaction_labels_pth\"]\n",
    "\n",
    "# up_dir, processed_dir, DSdataset_name, data_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/home/skyriakos/chemprop_run/git/deepadr\n",
      "/cluster/home/skyriakos/chemprop_run/git/data/processed/TWOSIDES/data_v1\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "targetdata_dir_raw = create_directory(os.path.join(targetdata_dir, \"raw\"))\n",
    "targetdata_dir_processed = create_directory(os.path.join(targetdata_dir, \"processed\"))\n",
    "# # ReaderWriter.dump_data(dpartitions, os.path.join(targetdata_dir, 'data_partitions.pkl'))\n",
    "print(targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.3 ms, sys: 652 ms, total: 660 ms\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = MoleculeDataset(root=targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MoleculeDataset(149878):\n",
      "====================\n",
      "Number of graphs: 149878\n",
      "Number of features: 9\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data0 = dataset[0]  # Get the first graph object.\n",
    "\n",
    "# print()\n",
    "# print(data)\n",
    "# print('=============================================================')\n",
    "\n",
    "# # Gather some statistics about the first graph.\n",
    "# print(f'Number of nodes: {data.num_nodes}')\n",
    "# print(f'Number of edges: {data.num_edges}')\n",
    "# print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "# print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "# print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairData(edge_attr_a=[52, 3], edge_attr_b=[22, 3], edge_index_a=[2, 52], edge_index_b=[2, 22], id=[1], x_a=[24, 9], x_b=[12, 9], y=[1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149878"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_dataset = dataset\n",
    "\n",
    "smaller_dataset_len = int(len(dataset)/5)\n",
    "used_dataset = dataset[:smaller_dataset_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_frac = [0.7, 0.1, 0.2]\n",
    "assert sum(train_val_test_frac) == 1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "used_dataset = used_dataset.shuffle()\n",
    "\n",
    "num_train = round(train_val_test_frac[0] * len(used_dataset)) \n",
    "num_trainval = round((train_val_test_frac[0]+train_val_test_frac[1]) * len(used_dataset))\n",
    "\n",
    "train_dataset = used_dataset[:num_train]\n",
    "val_dataset = used_dataset[num_train:num_trainval]\n",
    "test_dataset = used_dataset[num_trainval:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 20982\n",
      "Number of val graphs: 2998\n",
      "Number of test graphs: 5995\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of val graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairData(edge_attr_a=[66, 3], edge_attr_b=[66, 3], edge_index_a=[2, 66], edge_index_b=[2, 66], id=[1], x_a=[29, 9], x_b=[30, 9], y=[1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, follow_batch=['x_a', 'x_b'])\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, follow_batch=['x_a', 'x_b'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, follow_batch=['x_a', 'x_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_intermediate_dimension = 64\n",
    "emb_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"testGCN\"\n",
    "\n",
    "# deepadr_model = testGCN(num_node_features=dataset.num_node_features, \n",
    "#             hidden_channels=64, \n",
    "#             num_classes=model_intermediate_dimension)\n",
    "# print(deepadr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ogb\"\n",
    "\n",
    "gnn_model = GNN(gnn_type = 'gcn', \n",
    "                    num_tasks = dataset.num_classes, \n",
    "                    num_layer = 5, \n",
    "                    emb_dim = emb_dim, \n",
    "                    drop_ratio = 0.5, \n",
    "                    virtual_node = False,\n",
    "                    with_edge_attr=False,\n",
    "                    return_multilayer = True).to(device_gpu)\n",
    "#print(deepadr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embed_dim = None\n",
    "num_attn_heads = 2\n",
    "num_transformer_units = 1\n",
    "p_dropout = 0.3\n",
    "nonlin_func = nn.ReLU()\n",
    "mlp_embed_factor = 2\n",
    "pooling_mode = 'attn'\n",
    "\n",
    "dist_opt = 'cosine'\n",
    "l2_reg = 1e-6\n",
    "batch_size = 1000\n",
    "num_epochs = 100\n",
    "loss_w = 0.05\n",
    "margin_v = 1.\n",
    "\n",
    "transformer_model = DeepAdr_Transformer(input_size=emb_dim,\n",
    "                                        input_embed_dim=input_embed_dim,\n",
    "                                        num_attn_heads=num_attn_heads,\n",
    "                                        mlp_embed_factor=mlp_embed_factor,\n",
    "                                        nonlin_func=nonlin_func,\n",
    "                                        pdropout=p_dropout,\n",
    "                                        num_transformer_units=num_transformer_units,\n",
    "                                        pooling_mode=pooling_mode).to(device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    }
   ],
   "source": [
    "deepadr_siamese = DeepAdr_SiameseTrf(input_dim=emb_dim,\n",
    "                                   dist=dist_opt,\n",
    "                                   num_classes=dataset.num_classes).to(device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_param = list(gnn_model.parameters()) + list(transformer_model.parameters()) + list(deepadr_siamese.parameters())\n",
    "\n",
    "models = [(gnn_model, f'{model_name}_GNN'),\n",
    "          (transformer_model, f'{model_name}_Transformer'),\n",
    "          (deepadr_siamese, f'{model_name}_Siamese')]\n",
    "#models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Javascript\n",
    "# display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "optimizer = torch.optim.Adam(models_param, lr=0.001)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# loss_nlll = torch.nn.NLLLoss(weight=class_weights, reduction='mean')  # negative log likelihood loss\n",
    "loss_nlll = torch.nn.NLLLoss(reduction='mean')  # negative log likelihood loss\n",
    "loss_contrastive = ContrastiveLoss(0.5, reduction='mean')\n",
    "fdtype = torch.float32\n",
    "loss_w = 0.1\n",
    "\n",
    "# evaluator = Evaluator(DSdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for m, m_name in models:\n",
    "        m.train()\n",
    "\n",
    "        #            for i_batch, samples_batch in enumerate(data_loader):\n",
    "\n",
    "#     for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "    for i_batch, batch in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device_gpu)\n",
    "#         print(\"running batch:\", i_batch)\n",
    "        # x, edge_index, edge_attr, batch\n",
    "        h_a = gnn_model(batch.x_a, batch.edge_index_a, batch.edge_attr_a, batch.x_a_batch)\n",
    "        h_b = gnn_model(batch.x_b, batch.edge_index_b, batch.edge_attr_b, batch.x_b_batch)\n",
    "        \n",
    "        z_a, fattn_w_scores_a = transformer_model(h_a)\n",
    "        z_b, fattn_w_scores_b = transformer_model(h_b)\n",
    "        \n",
    "#         print(\"h_a shape:\", h_a.shape)\n",
    "#         print(\"z_a shape:\", z_a.shape)\n",
    "        \n",
    "        logsoftmax_scores, dist = deepadr_siamese(z_a, z_b)\n",
    "#         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "#         loss = criterion(out, samples_batch.y)  # Compute the loss.\n",
    "        cl = loss_nlll(logsoftmax_scores, batch.y)            \n",
    "        dl = loss_contrastive(dist.reshape(-1), batch.y.type(fdtype))          \n",
    "        loss = loss_w*cl + (1-loss_w)*dl\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def eval(loader, dsettype):\n",
    "    for m, m_name in models:\n",
    "        m.eval()\n",
    "        \n",
    "    pred_class = []\n",
    "    ref_class = []\n",
    "    prob_scores = []\n",
    "    \n",
    "#     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "    for i_batch, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device_gpu)\n",
    "#         out = model(data.x, data.edge_index, data.batch)  \n",
    "        h_a = gnn_model(batch.x_a, batch.edge_index_a, batch.edge_attr_a, batch.x_a_batch)\n",
    "        h_b = gnn_model(batch.x_b, batch.edge_index_b, batch.edge_attr_b, batch.x_b_batch)\n",
    "        \n",
    "        z_a, fattn_w_scores_a = transformer_model(h_a)\n",
    "        z_b, fattn_w_scores_b = transformer_model(h_b)\n",
    "        \n",
    "#         logsoftmax_scores, dist = deepadr_siamese(z_a, z_b)\n",
    "        \n",
    "#         __, y_pred_clss = torch.max(logsoftmax_scores, -1)\n",
    "#         y_pred_prob  = torch.exp(logsoftmax_scores.detach().cpu()).numpy()\n",
    "\n",
    "#         pred_class.extend(y_pred_clss.view(-1).tolist())\n",
    "#         ref_class.extend(batch.y.view(-1).tolist())\n",
    "# #         prob_scores.append(y_pred_prob)\n",
    "#         prob_scores.extend(y_pred_prob.view(-1).tolist())\n",
    "    \n",
    "        logsoftmax_scores, dist = deepadr_siamese(z_a, z_b)\n",
    "\n",
    "        __, y_pred_clss = torch.max(logsoftmax_scores, -1)\n",
    "\n",
    "        y_pred_prob  = torch.exp(logsoftmax_scores.detach().cpu()).numpy()\n",
    "\n",
    "        pred_class.extend(y_pred_clss.view(-1).tolist())\n",
    "        ref_class.extend(batch.y.view(-1).tolist())\n",
    "        prob_scores.append(y_pred_prob)\n",
    "\n",
    "    prob_scores_arr = np.concatenate(prob_scores, axis=0)\n",
    "    modelscore = perfmetric_report(pred_class, ref_class, prob_scores_arr[:,1], epoch,\n",
    "                                  outlog = os.path.join(targetdata_dir_processed, dsettype + \".log\"))\n",
    "#     modelscore = perfmetric_report(pred_class, ref_class, prob_scores, epoch, \"\")        \n",
    "    \n",
    "#         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "#         correct += int((pred == samples_batch.y).sum())  # Check against ground-truth labels.\n",
    "#     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "    return modelscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   0%|          | 0/656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 3/656 [00:00<01:45,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   1%|          | 7/656 [00:00<00:54, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 11/656 [00:00<00:41, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 15/656 [00:01<00:39, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   3%|▎         | 19/656 [00:01<00:37, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   4%|▎         | 23/656 [00:01<00:36, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   4%|▍         | 27/656 [00:01<00:34, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   5%|▍         | 31/656 [00:02<00:34, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   5%|▌         | 35/656 [00:02<00:33, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   6%|▌         | 39/656 [00:02<00:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   7%|▋         | 43/656 [00:02<00:34, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:   7%|▋         | 45/656 [00:02<00:36, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   7%|▋         | 49/656 [00:03<00:37, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   8%|▊         | 53/656 [00:03<00:35, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   9%|▊         | 57/656 [00:03<00:34, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   9%|▉         | 61/656 [00:03<00:35, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  10%|▉         | 65/656 [00:04<00:33, 17.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  11%|█         | 69/656 [00:04<00:37, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  11%|█         | 73/656 [00:04<00:36, 16.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  12%|█▏        | 77/656 [00:04<00:34, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  12%|█▏        | 81/656 [00:05<00:33, 17.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  13%|█▎        | 85/656 [00:05<00:32, 17.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  14%|█▎        | 89/656 [00:05<00:31, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  14%|█▍        | 93/656 [00:05<00:31, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  14%|█▍        | 95/656 [00:05<00:32, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  15%|█▌        | 99/656 [00:06<00:35, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  16%|█▌        | 103/656 [00:06<00:32, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  16%|█▋        | 107/656 [00:06<00:31, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  17%|█▋        | 109/656 [00:06<00:31, 17.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  17%|█▋        | 113/656 [00:07<00:37, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  18%|█▊        | 117/656 [00:07<00:34, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  18%|█▊        | 121/656 [00:07<00:31, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  19%|█▉        | 125/656 [00:07<00:30, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  20%|█▉        | 129/656 [00:07<00:30, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  20%|██        | 133/656 [00:08<00:29, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  21%|██        | 137/656 [00:08<00:29, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  21%|██▏       | 141/656 [00:08<00:29, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  22%|██▏       | 145/656 [00:08<00:29, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  23%|██▎       | 149/656 [00:09<00:33, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  23%|██▎       | 153/656 [00:09<00:30, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  24%|██▍       | 157/656 [00:09<00:28, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  25%|██▍       | 161/656 [00:09<00:28, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  25%|██▌       | 165/656 [00:10<00:27, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  26%|██▌       | 169/656 [00:10<00:26, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  26%|██▌       | 171/656 [00:10<00:27, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  27%|██▋       | 177/656 [00:10<00:26, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  28%|██▊       | 181/656 [00:10<00:26, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  28%|██▊       | 185/656 [00:11<00:26, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  29%|██▉       | 189/656 [00:11<00:26, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  29%|██▉       | 193/656 [00:11<00:26, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  30%|███       | 197/656 [00:11<00:25, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  31%|███       | 201/656 [00:12<00:25, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  31%|███▏      | 205/656 [00:12<00:25, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  32%|███▏      | 209/656 [00:12<00:25, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  32%|███▏      | 213/656 [00:12<00:25, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  33%|███▎      | 217/656 [00:12<00:24, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  34%|███▎      | 221/656 [00:13<00:24, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  34%|███▍      | 225/656 [00:13<00:24, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  35%|███▍      | 229/656 [00:13<00:23, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  36%|███▌      | 233/656 [00:13<00:23, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  36%|███▌      | 235/656 [00:13<00:24, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  37%|███▋      | 241/656 [00:14<00:23, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  37%|███▋      | 245/656 [00:14<00:23, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  38%|███▊      | 249/656 [00:14<00:22, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  38%|███▊      | 251/656 [00:14<00:23, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  39%|███▉      | 255/656 [00:15<00:23, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  40%|███▉      | 261/656 [00:15<00:22, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  40%|████      | 265/656 [00:15<00:21, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  41%|████      | 269/656 [00:15<00:21, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  42%|████▏     | 273/656 [00:16<00:21, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  42%|████▏     | 277/656 [00:16<00:21, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  43%|████▎     | 281/656 [00:16<00:21, 17.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  43%|████▎     | 285/656 [00:16<00:20, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  44%|████▍     | 289/656 [00:17<00:20, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  45%|████▍     | 293/656 [00:17<00:20, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  45%|████▌     | 297/656 [00:17<00:20, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  46%|████▌     | 301/656 [00:17<00:19, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  46%|████▋     | 305/656 [00:17<00:19, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  47%|████▋     | 309/656 [00:18<00:19, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  48%|████▊     | 313/656 [00:18<00:18, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  48%|████▊     | 315/656 [00:18<00:20, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  49%|████▊     | 319/656 [00:18<00:20, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  49%|████▉     | 323/656 [00:18<00:19, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  50%|████▉     | 327/656 [00:19<00:18, 17.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  50%|█████     | 331/656 [00:19<00:18, 17.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  51%|█████     | 335/656 [00:19<00:18, 17.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  52%|█████▏    | 339/656 [00:19<00:17, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  52%|█████▏    | 343/656 [00:20<00:17, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  53%|█████▎    | 347/656 [00:20<00:17, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  54%|█████▎    | 351/656 [00:20<00:17, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  54%|█████▍    | 355/656 [00:20<00:16, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  55%|█████▍    | 359/656 [00:21<00:16, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  55%|█████▌    | 363/656 [00:21<00:16, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  56%|█████▌    | 367/656 [00:21<00:15, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  57%|█████▋    | 371/656 [00:21<00:16, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  57%|█████▋    | 375/656 [00:21<00:15, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  58%|█████▊    | 378/656 [00:22<00:16, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n",
      "h_a shape: torch.Size([32, 6, 300])\n",
      "z_a shape: torch.Size([32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2d8fd43c645d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     for data in train_loader:  # Iterate in batches over the training dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         print(\"running batch:\", i_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    185\u001b[0m         dataset at the specified indices.\"\"\"\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/graphnn/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_nodes__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_curve = []\n",
    "test_curve = []\n",
    "train_curve = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"=====Epoch {}\".format(epoch))\n",
    "    print('Training...')\n",
    "#     train(model, device, train_loader, optimizer, dataset.task_type)\n",
    "    train()\n",
    "\n",
    "    print('Evaluating...')\n",
    "#     train_perf = eval(model, device, train_loader, evaluator)\n",
    "#     valid_perf = eval(model, device, valid_loader, evaluator)\n",
    "#     test_perf = eval(model, device, test_loader, evaluator)\n",
    "    train_perf = eval(train_loader, dsettype=\"train\")\n",
    "    valid_perf = eval(valid_loader, dsettype=\"valid\")\n",
    "    test_perf = eval(test_loader, dsettype=\"test\")\n",
    "\n",
    "    print({'Train': train_perf, 'Validation': valid_perf, 'Test': test_perf})\n",
    "\n",
    "    train_curve.append(train_perf.s_aupr)\n",
    "    valid_curve.append(valid_perf.s_aupr)\n",
    "    test_curve.append(test_perf.s_aupr)\n",
    "\n",
    "# if 'classification' in dataset.task_type:\n",
    "best_val_epoch = np.argmax(np.array(valid_curve))\n",
    "best_train = max(train_curve)\n",
    "# else:\n",
    "#     best_val_epoch = np.argmin(np.array(valid_curve))\n",
    "#     best_train = min(train_curve)\n",
    "\n",
    "print('Finished training!')\n",
    "print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n",
    "print('Test score: {}'.format(test_curve[best_val_epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curves = pd.DataFrame(np.array([train_curve, valid_curve, test_curve]).T)\n",
    "df_curves.columns = ['train', 'valid', 'test']\n",
    "df_curves.index.name = \"epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[1, 1,1,1,2,2,2,2], [3,3,3,3, 4,4,4,4], [5,5,5,5, 6,6,6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 4, 4, 4, 4],\n",
       "        [5, 5, 5, 5, 6, 6, 6, 6]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [1, 1],\n",
       "         [2, 2],\n",
       "         [2, 2]],\n",
       "\n",
       "        [[3, 3],\n",
       "         [3, 3],\n",
       "         [4, 4],\n",
       "         [4, 4]],\n",
       "\n",
       "        [[5, 5],\n",
       "         [5, 5],\n",
       "         [6, 6],\n",
       "         [6, 6]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(b.shape[0],4,b.shape[1] //4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"h_graph_cat shape:\", h_graph_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datapartitions (i.e. train/val, test indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpartitions = get_stratified_partitions(y, num_folds=5, valid_set_portion=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "# targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "ReaderWriter.dump_data(dpartitions, os.path.join(targetdata_dir, 'data_partitions.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using masking and inference with gip computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gip_perfold = {}\n",
    "for fold_id in dpartitions:\n",
    "    masked_intermat = interaction_mat.copy()\n",
    "    masked_intermat = masked_intermat.astype(np.float)\n",
    "    for dsettype in ('validation', 'test'):\n",
    "        # get validation/test ddi pair indices\n",
    "        sids = dpartitions[fold_id][dsettype]\n",
    "        a = [sid_ddipairs_map[sid][0] for sid in sids]\n",
    "        b = [sid_ddipairs_map[sid][1] for sid in sids]\n",
    "        # set to nan\n",
    "        masked_intermat[tuple([a,b])] = np.nan\n",
    "        masked_intermat[tuple([b,a])] = np.nan\n",
    "        \n",
    "    intermat_infer_lst = []\n",
    "    nanw_mat_lst = []\n",
    "    for similarity_type in similarity_types:\n",
    "        print('similarity_type', similarity_type)\n",
    "        siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "        sim_mat = get_similarity_matrix(siminput_feat_pth, DSdataset_name)\n",
    "        imat_infer, nanw_m = impute_nan(masked_intermat, sim_mat, k=15)\n",
    "        intermat_infer_lst.append(imat_infer)\n",
    "        nanw_mat_lst.append(nanw_m)\n",
    "        \n",
    "    infer_mat_fus = weight_inferred_mat(nanw_mat_lst, intermat_infer_lst)\n",
    "\n",
    "    print('norm(infer_mat-interaction_mat)', np.linalg.norm(infer_mat_fus - interaction_mat))\n",
    "\n",
    "    # compute GIP here\n",
    "    gip_kernel = compute_gip_kernel(infer_mat_fus, 1., kernel_option)\n",
    "    print('norm(gip_kernel-interaction_mat)',np.linalg.norm(gip_kernel - interaction_mat))\n",
    "    t = gip_kernel-interaction_mat\n",
    "    print(np.sum(np.abs(t) > 0.5)/(t.size - t.shape[0]))\n",
    "    gip_perfold[fold_id] = gip_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features from similarity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if similarity matrix is symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_types = len(similarity_types)\n",
    "for similarity_type in similarity_types:\n",
    "    siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "    sim_mat = get_similarity_matrix(siminput_feat_pth, DSdataset_name)   \n",
    "    print(np.allclose(sim_mat, np.transpose(sim_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_types = len(similarity_types)\n",
    "X_feats = []\n",
    "for similarity_type in similarity_types:\n",
    "    siminput_feat_pth = os.path.join(up_dir, rawdata_dir, DSdataset_name, '{}{}'.format(similarity_type, fname_suffix))\n",
    "    X_feat = preprocess_features(siminput_feat_pth, DSdataset_name, fill_diag=None)   \n",
    "    X_feats.append(X_feat)\n",
    "X_feat_cat = np.concatenate(X_feats, axis=1)\n",
    "print(\"X_feat_cat\", X_feat_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_setvector_features(X_feat_cat, 2*num_sim_types)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = X[:,list(range(0,2*num_sim_types,2))].copy()\n",
    "X_b = X[:,list(range(1,2*num_sim_types,2))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddi.utilities import format_bytes\n",
    "print(format_bytes(X_feat_cat.size * X_feat_cat.itemsize))\n",
    "print(format_bytes(y.size * y.itemsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear unused objects\n",
    "del X_feats\n",
    "del X_feat_cat\n",
    "del X_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "device_gpu = get_device(True, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype is float32 since we will use sigmoid (binary outcome)\n",
    "y_tensor = torch.tensor(y, dtype = torch.int64, device = device_cpu) \n",
    "X_a = torch.tensor(X_a, dtype = torch.float32, device = device_cpu)\n",
    "X_b = torch.tensor(X_b, dtype = torch.float32, device = device_cpu)\n",
    "ddi_datatensor = DDIDataTensor(X_a, X_b, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdata_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "ReaderWriter.dump_tensor(X_a, os.path.join(targetdata_dir, 'X_a.torch'))\n",
    "ReaderWriter.dump_tensor(X_b, os.path.join(targetdata_dir, 'X_b.torch'))\n",
    "ReaderWriter.dump_tensor(y_tensor, os.path.join(targetdata_dir, 'y_tensor.torch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct GIP datatensor for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gip_dtensor_perfold = {}\n",
    "for fold_id in gip_perfold:\n",
    "    print('fold_id:', fold_id)\n",
    "    gip_mat = gip_perfold[fold_id]\n",
    "    print('gip_mat:', gip_mat.shape)\n",
    "    gip_feat = get_features_from_simmatrix(gip_mat)\n",
    "    gip_all = create_setvector_features(gip_feat, 2)\n",
    "    print('gip_all:', gip_all.shape)\n",
    "    X_a_gip = gip_all[:,list(range(0,2*1,2))].copy()\n",
    "    X_b_gip = gip_all[:,list(range(1,2*1,2))].copy()\n",
    "    print('X_a_gip:', X_a_gip.shape)\n",
    "    X_a_gip = torch.tensor(X_a_gip, dtype = torch.float32, device = device_cpu)\n",
    "    X_b_gip = torch.tensor(X_b_gip, dtype = torch.float32, device = device_cpu)\n",
    "    gip_datatensor = GIPDataTensor(X_a_gip, X_b_gip)\n",
    "    gip_dtensor_perfold[fold_id] = gip_datatensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump data on disk\n",
    "ReaderWriter.dump_tensor(gip_dtensor_perfold, os.path.join(targetdata_dir, 'gip_dtensor_perfold.torch'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
