{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "from tqdm import tqdm\n",
    "import hiplot as hip\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/data/chemprop_run/git/notebooks/AltModels\n",
      "/opt/data/chemprop_run/git\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# cwd_parent = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "cwd_parent = os.path.abspath(os.path.join(cwd, '../../'))\n",
    "print(cwd_parent)\n",
    "\n",
    "sys.path.append(cwd_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.run_workflow import *\n",
    "from deepadr.chemfeatures import *\n",
    "from deepadr.hyphelperflat import *\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf, ExpressionNN\n",
    "from ogb.graphproppred import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 1\n",
      "cuda:0, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "# device_gpu = get_device(True, index=0)\n",
    "\n",
    "# fdtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.9.1\n",
      "CUDA: 11.1\n",
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:03) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'total_thresh' #'total_thresh'\n",
    "score_val = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = f'DrugComb_{score}_{score_val}'\n",
    "\n",
    "# v_1: GNN\n",
    "# v_2: Alt Models (Baseline)\n",
    "data_fname = 'data_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "/opt/data/chemprop_run/git/data/processed/DrugComb_total_thresh_4/data_v2\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "targetdata_dir_raw = create_directory(os.path.join(targetdata_dir, \"raw\"))\n",
    "targetdata_dir_processed = create_directory(os.path.join(targetdata_dir, \"processed\"))\n",
    "targetdata_dir_exp = create_directory(os.path.join(targetdata_dir, \"experiments\"))\n",
    "print(targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFlat = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'X_flat.pkl'))\n",
    "y = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'y.pkl'))\n",
    "expression = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'expression.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 18])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xFlatMat = torch.stack([torch.cat(i) for i in list(xFlat.values())])\n",
    "xFlatMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        [ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        [ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        ...,\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537],\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537],\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 926])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat([xFlatMat, torch.tensor(expression)], dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 926])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25757,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_num: 0\n",
      "train data\n",
      "class: 0 norm count: 0.5764128559102675\n",
      "class: 1 norm count: 0.4235871440897325\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5764751552795031\n",
      "class: 1 norm count: 0.4235248447204969\n",
      "\n",
      "-------------------------\n",
      "fold_num: 1\n",
      "train data\n",
      "class: 0 norm count: 0.5764128559102675\n",
      "class: 1 norm count: 0.4235871440897325\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5764751552795031\n",
      "class: 1 norm count: 0.4235248447204969\n",
      "\n",
      "-------------------------\n",
      "fold_num: 2\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n",
      "fold_num: 3\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n",
      "fold_num: 4\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_partitions = get_stratified_partitions(y,\n",
    "                                            num_folds=5,\n",
    "                                            valid_set_portion=0.1,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 18544\n",
      "Number of validation graphs: 2061\n",
      "Number of testing graphs: 5152\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['train'])))\n",
    "print(\"Number of validation graphs: \"+ str(len(fold_partitions[0]['validation'])))\n",
    "print(\"Number of testing graphs: \"+ str(len(fold_partitions[0]['test'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,    13,    16, ..., 25731, 25743, 25753])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_partitions[0]['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.numpy()\n",
    "y_np = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = compose(scaler.fit_transform, np.tanh, scaler.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np_norm = pipeline(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsynergy_input_size = x_np_norm.shape[1]\n",
    "deepsynergy_input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(range(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x151fe84f5400>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(torch.tensor(x_np_norm),torch.tensor(y), torch.tensor(ids))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25757, 926)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24771092, -0.16778051,  1.08542757, ..., -0.54753865,\n",
       "         1.00156924,  1.03730128],\n",
       "       [-0.52000601, -0.16778051,  0.88217988, ...,  0.13588219,\n",
       "         0.73121597, -0.67645394],\n",
       "       [-0.45946008, -0.16778051, -1.08878137, ...,  0.13588219,\n",
       "         0.73121597, -0.67645394],\n",
       "       ...,\n",
       "       [-0.78013155, -0.16778051,  1.38267408, ..., -1.10153143,\n",
       "         0.87510362, -0.63287422],\n",
       "       [ 0.06292934, -0.16778051, -0.09645783, ..., -0.6017063 ,\n",
       "         1.14208744, -1.22221096],\n",
       "       [-0.45708559, -0.16778051,  0.85635857, ..., -1.24509042,\n",
       "         1.20596684,  1.0750056 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(x_np_norm, fold_partitions[0]['test'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params total_thresh 4\n",
    "tp = {\n",
    "    \"batch_size\" : 300,\n",
    "    \"num_epochs\" : 100,\n",
    "    \n",
    "    \"emb_dim\" : 300,\n",
    "    \"gnn_type\" : \"gatv2\",\n",
    "    \"num_layer\" : 5,\n",
    "    \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "    \"input_embed_dim\" : None,\n",
    "    \"gene_embed_dim\": 1,\n",
    "    \"num_attn_heads\" : 2,\n",
    "    \"num_transformer_units\" : 1,\n",
    "    \"p_dropout\" : 0.3,\n",
    "#     \"nonlin_func\" : nn.ReLU(),\n",
    "    \"mlp_embed_factor\" : 2,\n",
    "    \"pooling_mode\" : 'attn',\n",
    "    \"dist_opt\" : 'cosine',\n",
    "\n",
    "    \"base_lr\" : 3e-5, #3e-4\n",
    "    \"max_lr_mul\": 5,\n",
    "    \"l2_reg\" : 1e-5,\n",
    "    \"loss_w\" : 1.,\n",
    "    \"margin_v\" : 1.,\n",
    "\n",
    "    \"expression_dim\" : 64,\n",
    "    \"expression_input_size\" : 908,\n",
    "    \"exp_H1\" : 8192,\n",
    "    \"exp_H2\" : 4096\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp['deepsynergy_input_size'] = deepsynergy_input_size\n",
    "tp['deepsynergy_input_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(queue, used_dataset, gpu_num, tphp, exp_dir, partition): #\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelperflat.run_exp_flat, args=(queue, used_dataset, gpu_num, tphp, exp_dir, partition)) #\n",
    "\n",
    "def create_q_process_attr(queue, x_np_norm, gpu_num, tphp, exp_dir, partition): #\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelperflat.run_attribution, args=(queue, x_np_norm, gpu_num, tphp, exp_dir, partition)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2022-06-21_15-53-07\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n",
      "gpu: cuda:0\n",
      "Dropout(p=0.5, inplace=False) Dropout(p=0.2, inplace=False)\n",
      "DS model:\n",
      " ExpressionNN(\n",
      "  (fc1): Linear(in_features=926, out_features=8192, bias=True)\n",
      "  (fc2): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  (drop_in): Dropout(p=0.2, inplace=False)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (log_softmax): LogSoftmax(dim=-1)\n",
      ")\n",
      "=====Epoch 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:01<00:00, 37.43it/s]\n",
      "Iteration:  18%|█▊        | 11/62 [00:00<00:00, 109.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 125.83it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 129.93it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 103.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train':  best_epoch_indx:0\n",
      " auc:0.7272338666632843 \n",
      " apur:0.6901857097822216 \n",
      " f1:0.6120552479154733 \n",
      " precision:0.6120162932790224 \n",
      " recall:0.6120942075111394 \n",
      ", 'Validation':  best_epoch_indx:0\n",
      " auc:0.7272338666632843 \n",
      " apur:0.6901857097822216 \n",
      " f1:0.6120552479154733 \n",
      " precision:0.6120162932790224 \n",
      " recall:0.6120942075111394 \n",
      ", 'Test':  best_epoch_indx:0\n",
      " auc:0.7272338666632843 \n",
      " apur:0.6901857097822216 \n",
      " f1:0.6120552479154733 \n",
      " precision:0.6120162932790224 \n",
      " recall:0.6120942075111394 \n",
      "}\n",
      "=====Epoch 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:01<00:00, 46.24it/s]\n",
      "Iteration:  19%|█▉        | 12/62 [00:00<00:00, 111.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 120.09it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 128.62it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 129.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train':  best_epoch_indx:1\n",
      " auc:0.753184332763493 \n",
      " apur:0.7143656811332795 \n",
      " f1:0.6106073097004672 \n",
      " precision:0.6631845993135352 \n",
      " recall:0.5657542966263527 \n",
      ", 'Validation':  best_epoch_indx:1\n",
      " auc:0.7531843327634928 \n",
      " apur:0.7143656811332795 \n",
      " f1:0.6106073097004672 \n",
      " precision:0.6631845993135352 \n",
      " recall:0.5657542966263527 \n",
      ", 'Test':  best_epoch_indx:1\n",
      " auc:0.7531843327634928 \n",
      " apur:0.7143656811332795 \n",
      " f1:0.6106073097004672 \n",
      " precision:0.6631845993135352 \n",
      " recall:0.5657542966263527 \n",
      "}\n",
      "=====Epoch 2\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:01<00:00, 46.27it/s]\n",
      "Iteration:  19%|█▉        | 12/62 [00:00<00:00, 113.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 109.62it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 131.43it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 132.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train':  best_epoch_indx:2\n",
      " auc:0.7597098369210534 \n",
      " apur:0.7281490337463927 \n",
      " f1:0.6480096501809409 \n",
      " precision:0.615702005730659 \n",
      " recall:0.6838956078930617 \n",
      ", 'Validation':  best_epoch_indx:2\n",
      " auc:0.7597098369210534 \n",
      " apur:0.7281490337463927 \n",
      " f1:0.6480096501809409 \n",
      " precision:0.615702005730659 \n",
      " recall:0.6838956078930617 \n",
      ", 'Test':  best_epoch_indx:2\n",
      " auc:0.7597098428761216 \n",
      " apur:0.7281490373162784 \n",
      " f1:0.6480096501809409 \n",
      " precision:0.615702005730659 \n",
      " recall:0.6838956078930617 \n",
      "}\n",
      "=====Epoch 3\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:01<00:00, 46.33it/s]\n",
      "Iteration:  19%|█▉        | 12/62 [00:00<00:00, 113.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 128.33it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 132.10it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 113.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train':  best_epoch_indx:3\n",
      " auc:0.7696107451820968 \n",
      " apur:0.73424683242553 \n",
      " f1:0.650700861147778 \n",
      " precision:0.6426620312888006 \n",
      " recall:0.6589433481858689 \n",
      ", 'Validation':  best_epoch_indx:3\n",
      " auc:0.7696107451820968 \n",
      " apur:0.73424683242553 \n",
      " f1:0.650700861147778 \n",
      " precision:0.6426620312888006 \n",
      " recall:0.6589433481858689 \n",
      ", 'Test':  best_epoch_indx:3\n",
      " auc:0.7696107451820968 \n",
      " apur:0.73424683242553 \n",
      " f1:0.650700861147778 \n",
      " precision:0.6426620312888006 \n",
      " recall:0.6589433481858689 \n",
      "}\n",
      "=====Epoch 4\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:01<00:00, 46.33it/s]\n",
      "Iteration:  19%|█▉        | 12/62 [00:00<00:00, 113.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 127.84it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 131.38it/s]\n",
      "Iteration: 100%|██████████| 62/62 [00:00<00:00, 132.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train':  best_epoch_indx:4\n",
      " auc:0.7723023049865538 \n",
      " apur:0.7372253533909892 \n",
      " f1:0.639273582440554 \n",
      " precision:0.6565141553736751 \n",
      " recall:0.622915340547422 \n",
      ", 'Validation':  best_epoch_indx:4\n",
      " auc:0.7723023049865538 \n",
      " apur:0.7372253533909892 \n",
      " f1:0.639273582440554 \n",
      " precision:0.6565141553736751 \n",
      " recall:0.622915340547422 \n",
      ", 'Test':  best_epoch_indx:4\n",
      " auc:0.7723023049865538 \n",
      " apur:0.7372253533909892 \n",
      " f1:0.639273582440554 \n",
      " precision:0.6565141553736751 \n",
      " recall:0.622915340547422 \n",
      "}\n",
      "Finished training!\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 0\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "q_processes = []\n",
    "\n",
    "# partition = fold_partitions[0]\n",
    "time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "print(\"Start: \" + time_stamp)\n",
    "\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "#     device_gpu = get_device(True, index=q_i)\n",
    "    partition = fold_partitions[q_i]\n",
    "    exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"fold_\"+str(q_i)+\"_\"+time_stamp))\n",
    "    create_directory(os.path.join(exp_dir, \"predictions\"))\n",
    "    create_directory(os.path.join(exp_dir, \"modelstates\"))\n",
    "\n",
    "#     tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "    \n",
    "    q_process = create_q_process(queue, dataset, q_i, tp, exp_dir, partition)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "# for q_i in range(len(hyperparam_space)):\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "#     if(spawned_processes < len(hyperparam_space)):\n",
    "# #         device_gpu = get_device(True, index=q_i)\n",
    "#         time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#         exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "#         tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "\n",
    "#         q_process = create_q_process(queue, used_dataset, released_gpu_num, tphp, exp_dir, partition)\n",
    "#         q_processes.append(q_process)\n",
    "#         spawn_q_process(q_process)\n",
    "#         spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2022-06-21_15-53-35\n"
     ]
    }
   ],
   "source": [
    "print(\"End: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stamp: 2022-06-21_15-53-07\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      ">>> spawning hyperparam search process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/graphnn/lib/python3.9/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5152 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: cuda:0\n",
      "Dropout(p=0.5, inplace=False) Dropout(p=0.2, inplace=False)\n",
      "DS model:\n",
      " ExpressionNN(\n",
      "  (fc1): Linear(in_features=926, out_features=8192, bias=True)\n",
      "  (fc2): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  (drop_in): Dropout(p=0.2, inplace=False)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (log_softmax): LogSoftmax(dim=-1)\n",
      ")\n",
      "Loading pre-trained model from: /opt/data/chemprop_run/git/data/processed/DrugComb_total_thresh_4/data_v2/experiments/fold_0_2022-06-21_15-53-07/modelstates/deepsynergy_model_statedict.pt\n",
      "Starting attr calc...\n",
      "<<< joined hyperparam search process\n",
      "released_gpu_num: 0\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "# q_attr = mp.Queue()\n",
    "q_processes = []\n",
    "\n",
    "l_attr = []\n",
    "\n",
    "# partition = fold_partitions[0]\n",
    "# time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "print(\"Time stamp: \" + time_stamp)\n",
    "\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "#     device_gpu = get_device(True, index=q_i)\n",
    "    partition = fold_partitions[q_i]\n",
    "    exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"fold_\"+str(q_i)+\"_\"+time_stamp))\n",
    "#     create_directory(os.path.join(exp_dir, \"predictions\"))\n",
    "#     create_directory(os.path.join(exp_dir, \"modelstates\"))\n",
    "    create_directory(os.path.join(exp_dir, \"attributions\"))\n",
    "\n",
    "\n",
    "#     tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "    \n",
    "    q_process = create_q_process_attr(queue, x_np_norm, q_i, tp, exp_dir, partition)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "# for q_i in range(len(hyperparam_space)):\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "#     l_attr.append(q_attr.get())\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "#     if(spawned_processes < len(hyperparam_space)):\n",
    "# #         device_gpu = get_device(True, index=q_i)\n",
    "#         time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#         exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "#         tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "\n",
    "#         q_process = create_q_process(queue, used_dataset, released_gpu_num, tphp, exp_dir, partition)\n",
    "#         q_processes.append(q_process)\n",
    "#         spawn_q_process(q_process)\n",
    "#         spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2022-06-21_15-54-26\n"
     ]
    }
   ],
   "source": [
    "print(\"End: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "exp_dirs = glob.glob(targetdata_dir_exp+\"/fold_*_\"+time_stamp)\n",
    "len(exp_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrAlgName = 'IntegratedGradients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = []\n",
    "\n",
    "for edir in exp_dirs:\n",
    "    fold = edir.split(\"/\")[-1].split('_')[1]\n",
    "    fold_attr = ReaderWriter.read_tensor(os.path.join(edir, 'attributions', f'{attrAlgName}_attributions.tensor'), device_cpuvisualize_importances(feature_names, np.mean(attr, axis=0)))\n",
    "    attributions = fold_attr.detach().cpu().numpy()\n",
    "    folds.append(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5152, 926)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(folds[0], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/snap-stanford/ogb/blob/68a303f320220cda859e83e3a8660f2b9debedf6/ogb/utils/features.py#L52\n",
    "\n",
    "atomic_features = ['AtomicNum', 'ChiralTag', 'TotalDegree', \n",
    "                   'FormalCharge', 'TotalNumHs', 'NumRadicalElectrons',\n",
    "                   'Hybridization', 'IsAromatic', 'IsInRing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_prefix(l, pre):\n",
    "    return [pre+i for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_gex = pd.read_csv('../../data/preprocessing/gene_gex.tsv', sep='\\t')\n",
    "all_feat = list_prefix(atomic_features, \"Drug1_\")+list_prefix(atomic_features, \"Drug2_\")+list(gene_gex.GENE_SYMBOLS)\n",
    "len(all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print importances and visualize distribution\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Feature Importances\n",
      "Drug1_AtomicNum :  -0.003\n",
      "Drug1_ChiralTag :  -0.002\n",
      "Drug1_TotalDegree :  -0.004\n",
      "Drug1_FormalCharge :  -0.002\n",
      "Drug1_TotalNumHs :  -0.003\n",
      "Drug1_NumRadicalElectrons :  0.000\n",
      "Drug1_Hybridization :  -0.001\n",
      "Drug1_IsAromatic :  -0.002\n",
      "Drug1_IsInRing :  -0.001\n",
      "Drug2_AtomicNum :  -0.007\n",
      "Drug2_ChiralTag :  -0.001\n",
      "Drug2_TotalDegree :  -0.004\n",
      "Drug2_FormalCharge :  -0.001\n",
      "Drug2_TotalNumHs :  -0.002\n",
      "Drug2_NumRadicalElectrons :  -0.003\n",
      "Drug2_Hybridization :  0.000\n",
      "Drug2_IsAromatic :  0.001\n",
      "Drug2_IsInRing :  -0.001\n",
      "TSPAN6 :  -0.000\n",
      "SCYL3 :  -0.000\n",
      "BAD :  0.000\n",
      "LAP3 :  -0.000\n",
      "SNX11 :  -0.000\n",
      "CASP10 :  -0.000\n",
      "CFLAR :  -0.000\n",
      "FKBP4 :  -0.000\n",
      "RBM6 :  -0.000\n",
      "SLC25A13 :  -0.000\n",
      "ST7 :  -0.000\n",
      "CIAPIN1 :  0.000\n",
      "MYCBP2 :  -0.000\n",
      "RALA :  0.000\n",
      "ETV1 :  0.000\n",
      "TBXA2R :  -0.000\n",
      "PAF1 :  -0.000\n",
      "ELAC2 :  -0.000\n",
      "PAFAH1B1 :  -0.000\n",
      "KIAA0100 :  -0.000\n",
      "TRAPPC6A :  -0.000\n",
      "E2F2 :  -0.000\n",
      "SYPL1 :  -0.000\n",
      "CYB561 :  -0.000\n",
      "UBE3C :  -0.001\n",
      "NCAPD2 :  -0.000\n",
      "NISCH :  -0.000\n",
      "BTK :  -0.000\n",
      "FYN :  0.000\n",
      "AKAP8L :  -0.000\n",
      "BRCA1 :  -0.000\n",
      "UBR7 :  0.000\n",
      "MVP :  -0.000\n",
      "HEBP1 :  -0.000\n",
      "MAMLD1 :  -0.000\n",
      "CAPN1 :  0.000\n",
      "BID :  -0.000\n",
      "NUDCD3 :  0.000\n",
      "ATP2C1 :  -0.000\n",
      "ZDHHC6 :  -0.000\n",
      "RNH1 :  0.000\n",
      "ALAS1 :  0.000\n",
      "DERA :  -0.000\n",
      "TOMM34 :  -0.000\n",
      "FAS :  -0.000\n",
      "CD44 :  -0.001\n",
      "TBPL1 :  -0.000\n",
      "GRN :  -0.000\n",
      "TIMP2 :  -0.000\n",
      "RAI14 :  -0.000\n",
      "PNKP :  -0.000\n",
      "EPHA3 :  -0.000\n",
      "DSG2 :  -0.000\n",
      "RFC2 :  -0.000\n",
      "MAPK9 :  0.000\n",
      "HERPUD1 :  -0.000\n",
      "RRP12 :  -0.000\n",
      "AKR7A2 :  -0.000\n",
      "LAMA3 :  -0.001\n",
      "TRAPPC3 :  -0.000\n",
      "ARID4B :  -0.000\n",
      "SYNE2 :  -0.000\n",
      "ATP11B :  -0.000\n",
      "TARBP1 :  0.000\n",
      "GNA15 :  -0.000\n",
      "ACAA1 :  -0.000\n",
      "SPAG4 :  -0.000\n",
      "CDH3 :  -0.000\n",
      "APPBP2 :  -0.000\n",
      "GPC1 :  -0.000\n",
      "LPAR2 :  -0.000\n",
      "HMG20B :  0.000\n",
      "TRAM2 :  -0.000\n",
      "ERBB3 :  -0.000\n",
      "ADAT1 :  -0.000\n",
      "PDIA5 :  -0.000\n",
      "SPEN :  -0.000\n",
      "MYLK :  -0.000\n",
      "PRKCQ :  -0.001\n",
      "MTHFD2 :  -0.000\n",
      "PPP2R5A :  -0.001\n",
      "ELAVL1 :  -0.000\n",
      "FGFR2 :  -0.001\n",
      "ISOC1 :  -0.000\n",
      "MTFR1 :  -0.000\n",
      "PHKA1 :  -0.000\n",
      "DHX29 :  -0.000\n",
      "DNTTIP2 :  0.000\n",
      "TP53BP1 :  -0.000\n",
      "RHOA :  -0.001\n",
      "IARS2 :  -0.000\n",
      "COASY :  -0.000\n",
      "NUP133 :  -0.000\n",
      "PIGB :  -0.000\n",
      "GNB5 :  -0.000\n",
      "RAB27A :  0.001\n",
      "IKBKAP :  -0.000\n",
      "NUCB2 :  -0.000\n",
      "JMJD6 :  -0.000\n",
      "POLB :  -0.000\n",
      "ST6GALNAC2 :  -0.000\n",
      "CSNK2A2 :  -0.000\n",
      "CDC42 :  -0.000\n",
      "NCK2 :  0.000\n",
      "MAP4K4 :  -0.000\n",
      "SNX13 :  -0.000\n",
      "PRKACA :  -0.000\n",
      "EPN2 :  -0.000\n",
      "SMC1A :  -0.000\n",
      "HSD17B10 :  -0.000\n",
      "P4HA2 :  0.000\n",
      "NFATC3 :  -0.001\n",
      "STK10 :  0.000\n",
      "SCARB1 :  -0.000\n",
      "KDM5A :  -0.000\n",
      "PTGS2 :  0.000\n",
      "IGF2BP2 :  -0.000\n",
      "GLI2 :  0.000\n",
      "EED :  -0.001\n",
      "ICAM3 :  -0.000\n",
      "RAP1GAP :  -0.000\n",
      "STXBP2 :  -0.000\n",
      "TM9SF3 :  -0.000\n",
      "NFKB2 :  -0.000\n",
      "IL4R :  -0.000\n",
      "UBE2A :  -0.001\n",
      "PIK3C3 :  0.000\n",
      "EDN1 :  0.000\n",
      "PCM1 :  -0.000\n",
      "MKNK1 :  -0.000\n",
      "FDFT1 :  -0.001\n",
      "PAFAH1B3 :  -0.000\n",
      "PGM1 :  -0.000\n",
      "EPB41L2 :  -0.000\n",
      "KEAP1 :  -0.000\n",
      "RAB21 :  -0.000\n",
      "SESN1 :  -0.000\n",
      "CNOT4 :  -0.000\n",
      "MOK :  -0.000\n",
      "CXCL2 :  -0.000\n",
      "MEF2C :  -0.000\n",
      "PTPRC :  -0.001\n",
      "ME2 :  -0.000\n",
      "ITGB5 :  -0.000\n",
      "KAT6A :  -0.000\n",
      "ITGAE :  0.000\n",
      "OXCT1 :  -0.000\n",
      "ZNF586 :  -0.000\n",
      "RPS5 :  -0.000\n",
      "FAT1 :  -0.000\n",
      "PPIE :  -0.000\n",
      "TXLNA :  -0.000\n",
      "MAP3K4 :  -0.001\n",
      "CPNE3 :  -0.001\n",
      "CTTN :  -0.000\n",
      "ORC1 :  -0.000\n",
      "MAST2 :  -0.000\n",
      "BAX :  -0.000\n",
      "MMP2 :  -0.000\n",
      "GNAS :  -0.000\n",
      "DNM1L :  -0.001\n",
      "AURKA :  -0.000\n",
      "GNA11 :  -0.000\n",
      "ANKRD10 :  -0.000\n",
      "PPP1R13B :  -0.000\n",
      "MAPKAPK5 :  -0.000\n",
      "PXN :  -0.000\n",
      "BIRC5 :  -0.000\n",
      "ICAM1 :  -0.000\n",
      "MCOLN1 :  -0.000\n",
      "AARS :  -0.000\n",
      "DLD :  -0.000\n",
      "WDR7 :  -0.000\n",
      "SPAG7 :  -0.000\n",
      "PSME1 :  0.000\n",
      "PPP2R3C :  -0.000\n",
      "PHGDH :  -0.000\n",
      "CDC45 :  -0.001\n",
      "HDAC6 :  -0.001\n",
      "HOOK2 :  -0.000\n",
      "BAMBI :  -0.000\n",
      "ABL1 :  -0.000\n",
      "CIRBP :  -0.000\n",
      "GADD45B :  -0.000\n",
      "CRKL :  -0.000\n",
      "MICALL1 :  -0.000\n",
      "XBP1 :  -0.000\n",
      "FBXO7 :  -0.000\n",
      "HMOX1 :  -0.000\n",
      "CERK :  -0.000\n",
      "ABHD4 :  -0.000\n",
      "POLE2 :  -0.000\n",
      "PYGL :  -0.000\n",
      "CGRRF1 :  -0.000\n",
      "ATP6V1D :  0.000\n",
      "TIMM9 :  -0.000\n",
      "GSTZ1 :  0.000\n",
      "SPTLC2 :  -0.001\n",
      "LGMN :  -0.000\n",
      "DHRS7 :  -0.000\n",
      "EIF5 :  -0.000\n",
      "PCK2 :  -0.001\n",
      "NFKBIA :  -0.001\n",
      "NFATC4 :  0.000\n",
      "CD40 :  -0.000\n",
      "MYBL2 :  -0.000\n",
      "RAE1 :  -0.000\n",
      "TPD52L2 :  -0.001\n",
      "TCFL5 :  0.000\n",
      "CDC25B :  -0.000\n",
      "TRIB3 :  -0.000\n",
      "MYL9 :  -0.000\n",
      "USP14 :  -0.000\n",
      "RNMT :  -0.000\n",
      "PSMD10 :  -0.000\n",
      "PGRMC1 :  -0.000\n",
      "SUV39H1 :  -0.000\n",
      "PLP2 :  -0.000\n",
      "SLC25A14 :  -0.000\n",
      "HTATSF1 :  -0.000\n",
      "CORO1A :  -0.000\n",
      "PHKB :  -0.000\n",
      "LYRM1 :  -0.000\n",
      "NUP93 :  -0.000\n",
      "ACD :  -0.000\n",
      "COG4 :  -0.000\n",
      "PLA2G15 :  -0.000\n",
      "AXIN1 :  -0.000\n",
      "NARFL :  -0.000\n",
      "DNAJA3 :  -0.000\n",
      "STX4 :  -0.000\n",
      "CCP110 :  -0.000\n",
      "CSK :  -0.000\n",
      "FAH :  0.000\n",
      "HOMER2 :  -0.000\n",
      "GABPB1 :  -0.001\n",
      "TJP1 :  -0.000\n",
      "DECR1 :  -0.000\n",
      "IKBKB :  -0.000\n",
      "TSTA3 :  -0.000\n",
      "ASAH1 :  0.000\n",
      "BNIP3L :  -0.000\n",
      "MAN2B1 :  -0.000\n",
      "ECH1 :  0.000\n",
      "NFKBIB :  -0.001\n",
      "RELB :  -0.000\n",
      "PIH1D1 :  -0.001\n",
      "PLEKHJ1 :  -0.000\n",
      "AKAP8 :  -0.000\n",
      "POP4 :  -0.000\n",
      "FSD1 :  -0.000\n",
      "POLR2I :  -0.001\n",
      "ETFB :  -0.000\n",
      "GRWD1 :  -0.000\n",
      "LIG1 :  -0.000\n",
      "LSR :  -0.000\n",
      "CDK6 :  -0.000\n",
      "H2AFV :  -0.000\n",
      "DNAJB6 :  -0.000\n",
      "GRB10 :  -0.000\n",
      "FKBP14 :  0.000\n",
      "STX1A :  -0.000\n",
      "CASP2 :  -0.000\n",
      "LSM5 :  -0.001\n",
      "SERPINE1 :  -0.000\n",
      "PLOD3 :  -0.000\n",
      "RPA3 :  0.000\n",
      "EZH2 :  -0.000\n",
      "MEST :  -0.000\n",
      "BLVRA :  -0.000\n",
      "RHEB :  -0.000\n",
      "PRKAG2 :  -0.000\n",
      "BCL7B :  -0.000\n",
      "YKT6 :  0.000\n",
      "C5 :  0.000\n",
      "DNM1 :  0.000\n",
      "TESK1 :  -0.000\n",
      "NPDC1 :  -0.000\n",
      "PDLIM1 :  -0.000\n",
      "GATA3 :  0.000\n",
      "RAB11FIP2 :  -0.000\n",
      "LIPA :  -0.000\n",
      "XPNPEP1 :  -0.000\n",
      "SMC3 :  0.000\n",
      "ZMIZ1 :  -0.000\n",
      "CASC3 :  -0.001\n",
      "RAD51C :  0.000\n",
      "RNF167 :  -0.000\n",
      "NUP88 :  -0.000\n",
      "BLMH :  -0.000\n",
      "SMARCD2 :  -0.000\n",
      "CYTH1 :  0.000\n",
      "CCL2 :  -0.000\n",
      "COL1A1 :  0.000\n",
      "VAT1 :  0.000\n",
      "DUSP3 :  -0.000\n",
      "TMEM97 :  -0.000\n",
      "DCUN1D4 :  0.000\n",
      "CHIC2 :  -0.000\n",
      "INPP4B :  0.001\n",
      "WFS1 :  -0.000\n",
      "TRIM2 :  -0.000\n",
      "MFSD10 :  -0.000\n",
      "UGDH :  -0.000\n",
      "HSPA8 :  -0.000\n",
      "CCND1 :  0.000\n",
      "CCDC86 :  -0.000\n",
      "TMEM109 :  -0.000\n",
      "BIRC2 :  -0.001\n",
      "PDHX :  -0.000\n",
      "SLC35F2 :  -0.000\n",
      "SLC11A2 :  -0.000\n",
      "MLEC :  -0.001\n",
      "CDKN1B :  -0.000\n",
      "RFC5 :  -0.000\n",
      "TIMELESS :  -0.000\n",
      "GAPDH :  -0.000\n",
      "COPS7A :  -0.000\n",
      "PTPN6 :  -0.001\n",
      "GOLT1B :  -0.000\n",
      "C2CD5 :  -0.000\n",
      "PPARD :  -0.000\n",
      "MCM3 :  0.000\n",
      "ZNF451 :  -0.000\n",
      "ASCC3 :  -0.001\n",
      "GMNN :  0.000\n",
      "CCND3 :  -0.000\n",
      "TBP :  -0.000\n",
      "DUSP22 :  -0.001\n",
      "SENP6 :  -0.000\n",
      "PAPD7 :  -0.000\n",
      "GHR :  -0.000\n",
      "HMGCS1 :  -0.000\n",
      "KIF20A :  -0.000\n",
      "NNT :  -0.001\n",
      "HMGCR :  -0.000\n",
      "GNPDA1 :  -0.000\n",
      "SKP1 :  -0.000\n",
      "NR3C1 :  -0.000\n",
      "TCERG1 :  -0.001\n",
      "CSNK1A1 :  0.000\n",
      "SMC4 :  0.000\n",
      "PCCB :  -0.000\n",
      "HES1 :  -0.000\n",
      "GNAI2 :  -0.000\n",
      "NPRL2 :  -0.001\n",
      "CBLB :  -0.001\n",
      "MAPKAPK3 :  -0.001\n",
      "ABCC5 :  -0.000\n",
      "MRPL19 :  -0.000\n",
      "STAT1 :  -0.000\n",
      "PECR :  -0.000\n",
      "TXNDC9 :  -0.000\n",
      "ST3GAL5 :  -0.001\n",
      "KDM3A :  -0.000\n",
      "FHL2 :  -0.000\n",
      "STK25 :  -0.000\n",
      "ID2 :  0.000\n",
      "CEBPZ :  -0.000\n",
      "SLC1A4 :  -0.000\n",
      "TRAK2 :  -0.000\n",
      "NFE2L2 :  0.000\n",
      "MSH6 :  -0.000\n",
      "SPR :  -0.000\n",
      "SCP2 :  -0.001\n",
      "FAM20B :  -0.000\n",
      "ICMT :  -0.000\n",
      "ARHGEF2 :  -0.000\n",
      "PLA2G4A :  -0.000\n",
      "GADD45A :  -0.000\n",
      "RGS2 :  -0.000\n",
      "CRYZ :  -0.000\n",
      "LGALS8 :  -0.000\n",
      "SDHB :  0.000\n",
      "KDM5B :  -0.000\n",
      "GALE :  -0.000\n",
      "EBNA1BP2 :  -0.000\n",
      "CDC20 :  -0.000\n",
      "IPO13 :  0.000\n",
      "ATP6V0B :  -0.000\n",
      "PIK3R3 :  -0.000\n",
      "SLC35A3 :  -0.000\n",
      "STMN1 :  -0.000\n",
      "RPS6KA1 :  -0.000\n",
      "DHDDS :  -0.000\n",
      "NENF :  -0.000\n",
      "RPA2 :  -0.000\n",
      "KIF14 :  -0.000\n",
      "CAMSAP2 :  -0.000\n",
      "ATF6 :  -0.000\n",
      "CREB1 :  -0.000\n",
      "TMEM5 :  -0.001\n",
      "FOXO3 :  -0.000\n",
      "SPP1 :  -0.000\n",
      "ITGB1BP1 :  -0.000\n",
      "CCDC92 :  -0.000\n",
      "HEATR1 :  -0.000\n",
      "CTNNAL1 :  -0.000\n",
      "TGFB3 :  0.000\n",
      "DNMT3A :  -0.000\n",
      "IDE :  -0.000\n",
      "SMNDC1 :  -0.000\n",
      "PCMT1 :  -0.000\n",
      "ACAT2 :  -0.000\n",
      "DNAJC15 :  -0.000\n",
      "UFM1 :  -0.000\n",
      "EGR1 :  -0.000\n",
      "PLS1 :  -0.000\n",
      "SOCS2 :  -0.000\n",
      "DUSP4 :  0.000\n",
      "SORBS3 :  -0.000\n",
      "PTK2B :  0.000\n",
      "TBX2 :  -0.000\n",
      "SLC35B1 :  -0.000\n",
      "CAT :  -0.000\n",
      "ZMYM2 :  0.000\n",
      "PIK3CA :  -0.000\n",
      "PDS5A :  -0.001\n",
      "CXCR4 :  -0.000\n",
      "MRPS2 :  -0.000\n",
      "CISD1 :  -0.001\n",
      "ECD :  -0.000\n",
      "ACOT9 :  -0.000\n",
      "ATF1 :  -0.000\n",
      "CDK2 :  0.000\n",
      "LPGAT1 :  -0.000\n",
      "NCOA3 :  -0.000\n",
      "VAPB :  -0.000\n",
      "STAMBP :  -0.000\n",
      "USP22 :  -0.000\n",
      "SPDEF :  0.000\n",
      "SOX4 :  -0.000\n",
      "TM9SF2 :  -0.000\n",
      "BMP4 :  -0.000\n",
      "NUP85 :  -0.000\n",
      "MBOAT7 :  -0.000\n",
      "IL1B :  -0.000\n",
      "PAX8 :  -0.001\n",
      "RTN2 :  -0.000\n",
      "PSMF1 :  -0.000\n",
      "BECN1 :  0.000\n",
      "TRAP1 :  -0.001\n",
      "TIMM17B :  0.000\n",
      "KTN1 :  -0.000\n",
      "PIN1 :  -0.000\n",
      "FBXL12 :  -0.000\n",
      "SYNGR3 :  0.000\n",
      "MACF1 :  -0.000\n",
      "SMARCA4 :  -0.000\n",
      "TICAM1 :  -0.000\n",
      "PTPN12 :  -0.000\n",
      "GNAI1 :  -0.000\n",
      "ZFP36 :  0.000\n",
      "PAICS :  -0.001\n",
      "CALU :  -0.000\n",
      "CHN1 :  -0.000\n",
      "HAT1 :  -0.000\n",
      "CHAC1 :  -0.000\n",
      "ARPP19 :  -0.000\n",
      "LOXL1 :  -0.000\n",
      "DCTD :  0.000\n",
      "PARP2 :  -0.000\n",
      "SNX6 :  -0.000\n",
      "EAPP :  -0.000\n",
      "REEP5 :  -0.000\n",
      "ITFG1 :  0.000\n",
      "APOE :  -0.000\n",
      "XPO7 :  -0.000\n",
      "FCHO1 :  -0.000\n",
      "PAK4 :  -0.000\n",
      "DNMT1 :  -0.000\n",
      "PRR7 :  -0.000\n",
      "SH3BP5 :  -0.000\n",
      "NR1H2 :  0.000\n",
      "ACLY :  -0.000\n",
      "IL13RA1 :  -0.000\n",
      "TOP2A :  -0.000\n",
      "DNAJB1 :  -0.000\n",
      "LRRC41 :  -0.000\n",
      "PPARG :  -0.000\n",
      "ENOSF1 :  -0.000\n",
      "ARFIP2 :  -0.000\n",
      "RRP8 :  -0.000\n",
      "RPA1 :  -0.000\n",
      "SNAP25 :  -0.000\n",
      "PCNA :  -0.000\n",
      "KIAA0907 :  -0.000\n",
      "IGHMBP2 :  -0.000\n",
      "DPH2 :  -0.000\n",
      "WASF3 :  -0.000\n",
      "PIK3C2B :  -0.000\n",
      "CCNA1 :  -0.000\n",
      "TCEAL4 :  -0.000\n",
      "EPHB2 :  -0.000\n",
      "CNDP2 :  -0.000\n",
      "CCNB1 :  -0.000\n",
      "CDK7 :  -0.000\n",
      "BHLHE40 :  -0.000\n",
      "EDEM1 :  -0.000\n",
      "VAV3 :  -0.000\n",
      "PSRC1 :  0.000\n",
      "CCNH :  -0.000\n",
      "DDB2 :  -0.000\n",
      "ETS1 :  -0.000\n",
      "TMEM2 :  -0.000\n",
      "FBXO21 :  -0.001\n",
      "DMTF1 :  -0.000\n",
      "TES :  -0.000\n",
      "CDK4 :  -0.000\n",
      "PAN2 :  -0.000\n",
      "MAP7 :  -0.000\n",
      "KCNK1 :  0.000\n",
      "COG2 :  -0.000\n",
      "DNAJB2 :  -0.000\n",
      "CAB39 :  -0.000\n",
      "PWP1 :  -0.000\n",
      "SCRN1 :  -0.000\n",
      "BZW2 :  -0.000\n",
      "NMT1 :  -0.000\n",
      "EPRS :  -0.000\n",
      "YME1L1 :  -0.001\n",
      "TOR1A :  -0.000\n",
      "STXBP1 :  0.000\n",
      "TLR4 :  0.000\n",
      "PRPF4 :  0.000\n",
      "FPGS :  0.001\n",
      "TEX10 :  -0.000\n",
      "MYC :  -0.000\n",
      "RPS6 :  -0.000\n",
      "CNPY3 :  -0.000\n",
      "TFAP2A :  -0.000\n",
      "BPHL :  0.000\n",
      "IER3 :  -0.000\n",
      "PRCP :  0.000\n",
      "SLC37A4 :  -0.000\n",
      "MAP2K5 :  -0.001\n",
      "SQRDL :  -0.000\n",
      "NUSAP1 :  -0.001\n",
      "PAK6 :  -0.000\n",
      "ADAM10 :  -0.000\n",
      "SLC5A6 :  -0.000\n",
      "FBXO11 :  -0.000\n",
      "ANXA7 :  -0.000\n",
      "HERC6 :  -0.000\n",
      "CENPE :  -0.000\n",
      "HADH :  -0.000\n",
      "EGF :  -0.001\n",
      "DUSP6 :  -0.000\n",
      "RB1 :  -0.000\n",
      "MBNL2 :  0.000\n",
      "GTF2A2 :  -0.000\n",
      "TSPAN3 :  -0.000\n",
      "WDR61 :  -0.001\n",
      "TPM1 :  -0.000\n",
      "IGF1R :  -0.000\n",
      "IQGAP1 :  -0.000\n",
      "PMM2 :  -0.000\n",
      "TXNL4B :  -0.001\n",
      "NOL3 :  -0.000\n",
      "MBTPS1 :  -0.000\n",
      "CLTC :  -0.000\n",
      "NPC1 :  -0.000\n",
      "TP53 :  -0.000\n",
      "PMAIP1 :  -0.000\n",
      "PIP4K2B :  -0.000\n",
      "ERBB2 :  -0.000\n",
      "GRB7 :  -0.000\n",
      "PFKL :  -0.000\n",
      "SIRT3 :  -0.001\n",
      "IFNAR1 :  -0.001\n",
      "APP :  -0.000\n",
      "AKT1 :  -0.000\n",
      "NOSIP :  -0.001\n",
      "WDTC1 :  -0.001\n",
      "KIF2C :  -0.000\n",
      "PTPRF :  -0.000\n",
      "MTF2 :  -0.000\n",
      "ATP1B1 :  -0.000\n",
      "MPC2 :  -0.001\n",
      "CREG1 :  -0.000\n",
      "TMCO1 :  -0.000\n",
      "PPOX :  -0.000\n",
      "RFX5 :  -0.000\n",
      "IKBKE :  -0.000\n",
      "DYRK3 :  -0.000\n",
      "TP53BP2 :  -0.001\n",
      "SLC27A3 :  -0.000\n",
      "INTS3 :  -0.000\n",
      "SCCPDH :  0.000\n",
      "NVL :  -0.000\n",
      "PARP1 :  -0.000\n",
      "LBR :  -0.000\n",
      "DUSP11 :  -0.000\n",
      "RALB :  -0.000\n",
      "HSPD1 :  -0.000\n",
      "VGLL4 :  -0.000\n",
      "ATG3 :  -0.001\n",
      "TCTA :  -0.000\n",
      "ENOPH1 :  -0.000\n",
      "SNCA :  -0.000\n",
      "CCNA2 :  -0.000\n",
      "MYO10 :  -0.000\n",
      "SSBP2 :  -0.000\n",
      "RASA1 :  -0.000\n",
      "TNIP1 :  -0.001\n",
      "G3BP1 :  -0.000\n",
      "GFOD1 :  -0.000\n",
      "TNFRSF21 :  -0.001\n",
      "NFKBIE :  0.000\n",
      "EGFR :  -0.000\n",
      "IGFBP3 :  -0.000\n",
      "TLK2 :  -0.000\n",
      "CASK :  0.000\n",
      "EBP :  -0.000\n",
      "NSDHL :  -0.000\n",
      "POLR2K :  -0.000\n",
      "CDKN2A :  -0.000\n",
      "NOTCH1 :  -0.000\n",
      "USP6NL :  -0.000\n",
      "RSU1 :  -0.001\n",
      "PAK1 :  -0.000\n",
      "HYOU1 :  0.000\n",
      "EML3 :  -0.000\n",
      "CHEK1 :  -0.000\n",
      "YTHDF1 :  -0.001\n",
      "PLCB3 :  -0.000\n",
      "ALDOA :  -0.000\n",
      "HMGA2 :  -0.000\n",
      "ARID5B :  -0.000\n",
      "PRSS23 :  -0.000\n",
      "UBE3B :  -0.000\n",
      "INPP1 :  0.000\n",
      "SLC25A4 :  -0.000\n",
      "BAG3 :  -0.000\n",
      "MBNL1 :  -0.000\n",
      "PTPRK :  0.000\n",
      "CAST :  -0.000\n",
      "CETN3 :  -0.000\n",
      "RPIA :  -0.000\n",
      "HS2ST1 :  -0.000\n",
      "PPP2R5E :  0.000\n",
      "FAM69A :  -0.000\n",
      "TSEN2 :  -0.000\n",
      "CDK19 :  -0.001\n",
      "OXA1L :  -0.000\n",
      "FZD7 :  -0.000\n",
      "RRAGA :  -0.000\n",
      "DCK :  -0.000\n",
      "TIAM1 :  -0.000\n",
      "SUPV3L1 :  -0.000\n",
      "HK1 :  -0.000\n",
      "UBE2L6 :  0.000\n",
      "KAT6B :  0.000\n",
      "UTP14A :  -0.000\n",
      "MAPK13 :  0.000\n",
      "PHKG2 :  -0.000\n",
      "TATDN2 :  -0.000\n",
      "FZD1 :  0.000\n",
      "KIT :  -0.000\n",
      "TSC22D3 :  -0.000\n",
      "C2CD2 :  -0.000\n",
      "FAIM :  -0.000\n",
      "GDPD5 :  -0.000\n",
      "NIT1 :  -0.000\n",
      "CSRP1 :  -0.000\n",
      "CBR1 :  -0.001\n",
      "CBR3 :  -0.000\n",
      "PSMD4 :  -0.000\n",
      "EFCAB14 :  -0.000\n",
      "CALM3 :  -0.000\n",
      "DFFA :  -0.000\n",
      "NR2F6 :  -0.000\n",
      "RRP1B :  -0.001\n",
      "RALGDS :  -0.000\n",
      "SLC2A6 :  -0.000\n",
      "SHC1 :  -0.001\n",
      "ANO10 :  -0.000\n",
      "FGFR4 :  0.000\n",
      "CPSF4 :  -0.000\n",
      "VPS28 :  -0.000\n",
      "SQSTM1 :  -0.000\n",
      "BDH1 :  -0.000\n",
      "DUSP14 :  0.000\n",
      "CCNF :  -0.001\n",
      "AMDHD2 :  -0.000\n",
      "KLHL21 :  -0.000\n",
      "USP1 :  0.000\n",
      "SNX7 :  -0.000\n",
      "AGL :  -0.000\n",
      "DENND2D :  -0.000\n",
      "MAPKAPK2 :  -0.000\n",
      "SGCB :  -0.000\n",
      "VPS72 :  -0.000\n",
      "TGFBR2 :  -0.000\n",
      "GTPBP8 :  0.000\n",
      "TIPARP :  -0.000\n",
      "ABHD6 :  0.000\n",
      "APBB2 :  -0.000\n",
      "TOPBP1 :  -0.000\n",
      "RPN1 :  -0.000\n",
      "RPL39L :  -0.000\n",
      "PRKCD :  -0.001\n",
      "LRPAP1 :  -0.000\n",
      "CDC25A :  -0.000\n",
      "ZNF589 :  0.000\n",
      "LSM6 :  -0.001\n",
      "SLC25A46 :  -0.000\n",
      "CASP3 :  -0.000\n",
      "TERT :  -0.000\n",
      "SLC35A1 :  -0.001\n",
      "NOS3 :  -0.000\n",
      "ALDH7A1 :  -0.000\n",
      "PSIP1 :  0.000\n",
      "SYK :  -0.000\n",
      "NFIL3 :  -0.000\n",
      "DYNLT3 :  -0.000\n",
      "MELK :  -0.001\n",
      "KLHDC2 :  -0.000\n",
      "HPRT1 :  -0.000\n",
      "CASP7 :  -0.000\n",
      "PACSIN3 :  -0.001\n",
      "HTRA1 :  0.000\n",
      "CEP57 :  -0.000\n",
      "NOLC1 :  -0.000\n",
      "FRS2 :  -0.000\n",
      "PCBD1 :  0.000\n",
      "ILK :  -0.000\n",
      "KIAA0355 :  -0.001\n",
      "ATMIN :  -0.000\n",
      "BLCAP :  -0.000\n",
      "PEX11A :  -0.000\n",
      "TERF2IP :  -0.000\n",
      "PLK1 :  -0.000\n",
      "CLPX :  -0.000\n",
      "SMAD3 :  0.000\n",
      "PRR15L :  -0.000\n",
      "CRK :  -0.000\n",
      "FAM57A :  -0.000\n",
      "GLOD4 :  -0.000\n",
      "CD320 :  -0.000\n",
      "KCTD5 :  -0.000\n",
      "RAB4A :  -0.000\n",
      "MAPK1IP1L :  -0.000\n",
      "DDIT4 :  -0.000\n",
      "NT5DC2 :  -0.000\n",
      "KIF5C :  -0.000\n",
      "THAP11 :  -0.000\n",
      "COG7 :  -0.000\n",
      "RAB31 :  0.000\n",
      "STAT3 :  -0.000\n",
      "PKIG :  -0.000\n",
      "MAT2A :  -0.001\n",
      "PPIC :  -0.000\n",
      "ATF5 :  -0.001\n",
      "ADRB2 :  -0.000\n",
      "PTK2 :  -0.001\n",
      "CLIC4 :  -0.000\n",
      "DFFB :  -0.000\n",
      "RFNG :  -0.000\n",
      "CRTAP :  -0.000\n",
      "CDK1 :  -0.000\n",
      "FOS :  -0.000\n",
      "TMED10 :  -0.000\n",
      "NUDT9 :  -0.000\n",
      "ELOVL6 :  -0.000\n",
      "HSPA4 :  -0.000\n",
      "CDCA4 :  0.000\n",
      "FEZ2 :  -0.000\n",
      "RBKS :  -0.000\n",
      "SCAND1 :  -0.000\n",
      "GAA :  -0.000\n",
      "CANT1 :  -0.000\n",
      "POLR1C :  -0.000\n",
      "ZNF318 :  -0.000\n",
      "WIPF2 :  -0.000\n",
      "CLSTN1 :  -0.000\n",
      "ZNF274 :  -0.000\n",
      "TCEA2 :  -0.000\n",
      "BCL2 :  -0.000\n",
      "MALT1 :  -0.000\n",
      "ZNF131 :  -0.000\n",
      "C2CD2L :  -0.000\n",
      "ARNT2 :  -0.000\n",
      "RAD9A :  -0.000\n",
      "OXSR1 :  -0.000\n",
      "GLRX :  -0.000\n",
      "TRIB1 :  -0.000\n",
      "DAG1 :  -0.000\n",
      "SMARCC1 :  -0.000\n",
      "STAT5B :  -0.001\n",
      "NET1 :  0.000\n",
      "FUT1 :  0.000\n",
      "UBE2C :  -0.000\n",
      "ARHGAP1 :  -0.001\n",
      "CCNE2 :  -0.000\n",
      "CLTB :  -0.000\n",
      "DRAP1 :  0.000\n",
      "FOSL1 :  -0.000\n",
      "CCDC85B :  -0.000\n",
      "RUVBL1 :  0.000\n",
      "SFN :  0.000\n",
      "MSRA :  -0.000\n",
      "TUBB6 :  -0.000\n",
      "CHMP6 :  -0.001\n",
      "BNIP3 :  -0.000\n",
      "CDK5R1 :  -0.000\n",
      "TIMM22 :  -0.000\n",
      "JUN :  -0.001\n",
      "STAP2 :  0.000\n",
      "DDX10 :  -0.000\n",
      "P4HTM :  -0.000\n",
      "SUZ12 :  -0.000\n",
      "EXOSC4 :  -0.000\n",
      "AURKB :  -0.000\n",
      "RRS1 :  -0.000\n",
      "GATA2 :  -0.000\n",
      "RBM15B :  -0.000\n",
      "PUF60 :  -0.000\n",
      "NRIP1 :  -0.000\n",
      "ADO :  -0.000\n",
      "WRB :  -0.000\n",
      "MRPS16 :  -0.000\n",
      "EXT1 :  -0.000\n",
      "BACE2 :  0.000\n",
      "ADI1 :  -0.000\n",
      "TSKU :  -0.000\n",
      "ACBD3 :  -0.000\n",
      "MTA1 :  -0.000\n",
      "PYCR1 :  -0.000\n",
      "PSMG1 :  -0.000\n",
      "TMEM50A :  -0.000\n",
      "CHEK2 :  -0.000\n",
      "PRKX :  -0.000\n",
      "NIPSNAP1 :  -0.000\n",
      "CRELD2 :  0.000\n",
      "COPB2 :  -0.000\n",
      "FOXO4 :  -0.000\n",
      "PROS1 :  -0.000\n",
      "HIST2H2BE :  -0.000\n",
      "MUC1 :  0.000\n",
      "IKZF1 :  -0.000\n",
      "INSIG1 :  -0.000\n",
      "GPATCH8 :  0.000\n",
      "ZNF395 :  -0.000\n",
      "CHP1 :  -0.000\n",
      "COL4A1 :  -0.000\n",
      "USP7 :  -0.001\n",
      "EIF4EBP1 :  0.000\n",
      "UBQLN2 :  -0.000\n",
      "ARL4C :  0.000\n",
      "PLSCR1 :  -0.000\n",
      "S100A13 :  -0.000\n",
      "S100A4 :  -0.001\n",
      "PTPN1 :  -0.000\n",
      "EVL :  -0.000\n",
      "PIK3R4 :  -0.000\n",
      "HDAC2 :  0.000\n",
      "MMP1 :  -0.000\n",
      "TLE1 :  -0.000\n",
      "ARHGEF12 :  -0.000\n",
      "LAGE3 :  -0.001\n",
      "IGF2R :  -0.000\n",
      "SRC :  -0.000\n",
      "TBC1D9B :  -0.000\n",
      "GTF2E2 :  -0.000\n",
      "LRP10 :  -0.000\n",
      "PDGFA :  -0.000\n",
      "SPTAN1 :  -0.000\n",
      "ADH5 :  -0.000\n",
      "HIST1H2BK :  -0.000\n",
      "MPZL1 :  -0.000\n",
      "TFDP1 :  -0.000\n",
      "DDX42 :  -0.001\n",
      "SPRED2 :  0.000\n",
      "GFPT1 :  -0.001\n",
      "TXNRD1 :  -0.000\n",
      "CTNND1 :  0.000\n",
      "KLHL9 :  -0.000\n",
      "PNP :  -0.000\n",
      "FOXJ3 :  0.000\n",
      "UBE2J1 :  -0.000\n",
      "KIAA0753 :  -0.001\n",
      "DAXX :  -0.000\n",
      "PSMB8 :  -0.000\n",
      "HLA-DRA :  -0.000\n",
      "SKIV2L :  -0.000\n",
      "HSPA1A :  -0.000\n",
      "ABCF1 :  -0.000\n",
      "DDR1 :  -0.000\n",
      "TCTN1 :  -0.000\n",
      "TRIM13 :  -0.000\n",
      "RNPS1 :  -0.001\n",
      "HN1L :  0.000\n",
      "SACM1L :  -0.000\n",
      "MLLT11 :  -0.000\n",
      "NRAS :  -0.000\n",
      "CSNK1E :  -0.001\n",
      "TSPAN4 :  -0.000\n",
      "MYCBP :  -0.000\n",
      "FIS1 :  -0.000\n",
      "IFRD2 :  -0.000\n",
      "NPEPL1 :  -0.000\n",
      "CEBPD :  0.000\n",
      "PLEKHM1 :  -0.001\n",
      "MIF :  0.000\n",
      "PRAF2 :  -0.000\n",
      "LYN :  -0.000\n",
      "POLG2 :  -0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_importances(all_feat, np.mean(folds[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "summary_legacy() missing 1 required positional argument: 'shap_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_feat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: summary_legacy() missing 1 required positional argument: 'shap_values'"
     ]
    }
   ],
   "source": [
    "shap.summary_plot(features=all_feat, feature_names=all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
