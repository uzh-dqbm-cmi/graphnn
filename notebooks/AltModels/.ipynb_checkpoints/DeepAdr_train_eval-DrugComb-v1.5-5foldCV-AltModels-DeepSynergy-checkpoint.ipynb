{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "from tqdm import tqdm\n",
    "import hiplot as hip\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/data/chemprop_run/git/notebooks/AltModels\n",
      "/opt/data/chemprop_run/git\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# cwd_parent = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "cwd_parent = os.path.abspath(os.path.join(cwd, '../../'))\n",
    "print(cwd_parent)\n",
    "\n",
    "sys.path.append(cwd_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.run_workflow import *\n",
    "from deepadr.chemfeatures import *\n",
    "from deepadr.hyphelperflat import *\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf, ExpressionNN\n",
    "from ogb.graphproppred import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 5\n",
      "cuda:0, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:1, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:2, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:3, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:4, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "# device_gpu = get_device(True, index=0)\n",
    "\n",
    "# fdtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.9.1\n",
      "CUDA: 11.1\n",
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:03) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'total_thresh' #'total_thresh'\n",
    "score_val = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = f'DrugComb_{score}_{score_val}'\n",
    "\n",
    "# v_1: GNN\n",
    "# v_2: Alt Models (Baseline)\n",
    "data_fname = 'data_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "path_current_dir /opt/data/chemprop_run/git/deepadr\n",
      "/opt/data/chemprop_run/git/data/processed/DrugComb_total_thresh_4/data_v2\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "targetdata_dir_raw = create_directory(os.path.join(targetdata_dir, \"raw\"))\n",
    "targetdata_dir_processed = create_directory(os.path.join(targetdata_dir, \"processed\"))\n",
    "targetdata_dir_exp = create_directory(os.path.join(targetdata_dir, \"experiments\"))\n",
    "print(targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFlat = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'X_flat.pkl'))\n",
    "y = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'y.pkl'))\n",
    "expression = ReaderWriter.read_data(os.path.join(targetdata_dir_raw, 'expression.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xFlatMat = torch.stack([torch.cat(i) for i in list(xFlat.values())])\n",
    "xFlatMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        [ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        [ 0.1661,  0.2518,  1.3373,  ..., -0.4085,  0.8581,  0.8979],\n",
       "        ...,\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537],\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537],\n",
       "        [-0.0373, -1.4322,  1.5411,  ..., -1.2711,  1.2013,  0.9537]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 926])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat([xFlatMat, torch.tensor(expression)], dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25757, 926])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25757,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_num: 0\n",
      "train data\n",
      "class: 0 norm count: 0.5764128559102675\n",
      "class: 1 norm count: 0.4235871440897325\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5764751552795031\n",
      "class: 1 norm count: 0.4235248447204969\n",
      "\n",
      "-------------------------\n",
      "fold_num: 1\n",
      "train data\n",
      "class: 0 norm count: 0.5764128559102675\n",
      "class: 1 norm count: 0.4235871440897325\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5764751552795031\n",
      "class: 1 norm count: 0.4235248447204969\n",
      "\n",
      "-------------------------\n",
      "fold_num: 2\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n",
      "fold_num: 3\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n",
      "fold_num: 4\n",
      "train data\n",
      "class: 0 norm count: 0.5764356969533567\n",
      "class: 1 norm count: 0.4235643030466433\n",
      "validation data\n",
      "class: 0 norm count: 0.5764192139737991\n",
      "class: 1 norm count: 0.42358078602620086\n",
      "test data\n",
      "class: 0 norm count: 0.5763929334109882\n",
      "class: 1 norm count: 0.4236070665890118\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_partitions = get_stratified_partitions(y,\n",
    "                                            num_folds=5,\n",
    "                                            valid_set_portion=0.1,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 18544\n",
      "Number of validation graphs: 2061\n",
      "Number of testing graphs: 5152\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['train'])))\n",
    "print(\"Number of validation graphs: \"+ str(len(fold_partitions[0]['validation'])))\n",
    "print(\"Number of testing graphs: \"+ str(len(fold_partitions[0]['test'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.numpy()\n",
    "y_np = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = compose(scaler.fit_transform, np.tanh, scaler.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np_norm = pipeline(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepsynergy_input_size = x_np_norm.shape[1]\n",
    "deepsynergy_input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(range(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x14a05f333c10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(torch.tensor(x_np_norm),torch.tensor(y), torch.tensor(ids))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25757, 926)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,    13,    16, ..., 25731, 25743, 25753])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_partitions[0]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params total_thresh 4\n",
    "tp = {\n",
    "    \"batch_size\" : 300,\n",
    "    \"num_epochs\" : 100,\n",
    "    \n",
    "    \"emb_dim\" : 300,\n",
    "    \"gnn_type\" : \"gatv2\",\n",
    "    \"num_layer\" : 5,\n",
    "    \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "    \"input_embed_dim\" : None,\n",
    "    \"gene_embed_dim\": 1,\n",
    "    \"num_attn_heads\" : 2,\n",
    "    \"num_transformer_units\" : 1,\n",
    "    \"p_dropout\" : 0.3,\n",
    "#     \"nonlin_func\" : nn.ReLU(),\n",
    "    \"mlp_embed_factor\" : 2,\n",
    "    \"pooling_mode\" : 'attn',\n",
    "    \"dist_opt\" : 'cosine',\n",
    "\n",
    "    \"base_lr\" : 3e-5, #3e-4\n",
    "    \"max_lr_mul\": 5,\n",
    "    \"l2_reg\" : 1e-5,\n",
    "    \"loss_w\" : 1.,\n",
    "    \"margin_v\" : 1.,\n",
    "\n",
    "    \"expression_dim\" : 64,\n",
    "    \"expression_input_size\" : 908,\n",
    "    \"exp_H1\" : 8192,\n",
    "    \"exp_H2\" : 4096\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp['deepsynergy_input_size'] = deepsynergy_input_size\n",
    "tp['deepsynergy_input_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(queue, used_dataset, gpu_num, tphp, exp_dir, partition): #\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelperflat.run_exp_flat, args=(queue, used_dataset, gpu_num, tphp, exp_dir, partition)) #\n",
    "\n",
    "def create_q_process_attr(queue, x_np_norm, gpu_num, tphp, exp_dir, partition, labels): #\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelperflat.run_attribution, args=(queue, x_np_norm, gpu_num, tphp, exp_dir, partition, labels)) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.multiprocessing as mp\n",
    "# mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "# queue = mp.Queue()\n",
    "# q_processes = []\n",
    "\n",
    "# # partition = fold_partitions[0]\n",
    "# time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# print(\"Start: \" + time_stamp)\n",
    "\n",
    "# for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "# #     device_gpu = get_device(True, index=q_i)\n",
    "#     partition = fold_partitions[q_i]\n",
    "#     exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"fold_\"+str(q_i)+\"_\"+time_stamp))\n",
    "#     create_directory(os.path.join(exp_dir, \"predictions\"))\n",
    "#     create_directory(os.path.join(exp_dir, \"modelstates\"))\n",
    "\n",
    "# #     tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "    \n",
    "#     q_process = create_q_process(queue, dataset, q_i, tp, exp_dir, partition)\n",
    "#     q_processes.append(q_process)\n",
    "#     spawn_q_process(q_process)\n",
    "\n",
    "# spawned_processes = n_gpu\n",
    "    \n",
    "# # for q_i in range(len(hyperparam_space)):\n",
    "# for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "#     join_q_process(q_processes[q_i])\n",
    "#     released_gpu_num = queue.get()\n",
    "#     print(\"released_gpu_num:\", released_gpu_num)\n",
    "# #     if(spawned_processes < len(hyperparam_space)):\n",
    "# # #         device_gpu = get_device(True, index=q_i)\n",
    "# #         time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "# #         exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "# #         tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "\n",
    "# #         q_process = create_q_process(queue, used_dataset, released_gpu_num, tphp, exp_dir, partition)\n",
    "# #         q_processes.append(q_process)\n",
    "# #         spawn_q_process(q_process)\n",
    "# #         spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2022-06-28_16-38-32\n"
     ]
    }
   ],
   "source": [
    "print(\"End: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
