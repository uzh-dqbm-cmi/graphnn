{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "from tqdm import tqdm\n",
    "import hiplot as hip\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/notebooks/AltModels\n",
      "/cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# cwd_parent = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "cwd_parent = os.path.abspath(os.path.join(cwd, '../../'))\n",
    "print(cwd_parent)\n",
    "\n",
    "sys.path.append(cwd_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.run_workflow import *\n",
    "from deepadr.chemfeatures import *\n",
    "from deepadr.hyphelperv2VanillaGNN import *\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf, ExpressionNN\n",
    "from ogb.graphproppred import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs available: 5\n",
      "cuda:0, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:1, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:2, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:3, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n",
      "cuda:4, name:NVIDIA GeForce GTX 1080 Ti\n",
      "total memory available: 10.91656494140625 GB\n",
      "total memory allocated on device: 0.0 GB\n",
      "max memory allocated on device: 0.0 GB\n",
      "total memory cached on device: 0.0 GB\n",
      "max memory cached  on device: 0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_available_cuda_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "# n_gpu = 1\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "# device_gpu = get_device(True, index=0)\n",
    "\n",
    "# fdtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.11.0+cu115\n",
      "CUDA: 11.5\n",
      "3.8.10 (default, Jun 22 2022, 20:18:18) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options: \n",
    "# 'total_thresh' + 4,3,2\n",
    "# 'loewe_thresh', 'hsa_thresh', 'bliss_thresh', 'zip_thresh' + 1\n",
    "\n",
    "score = 'hsa_thresh'\n",
    "score_val = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSdataset_name = f'DrugComb_{score}_{score_val}'\n",
    "\n",
    "data_fname = 'data_v1' # v2 for baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/deepadr\n",
      "path_current_dir /cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/deepadr\n",
      "/cluster/work/medinfmk/lm1-homes/skyriakos-lm1-home/data_to_migrate/chemprop_run/git/data/processed/DrugComb_hsa_thresh_1/data_v1\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, DSdataset_name, data_fname))\n",
    "targetdata_dir_raw = create_directory(os.path.join(targetdata_dir, \"raw\"))\n",
    "targetdata_dir_processed = create_directory(os.path.join(targetdata_dir, \"processed\"))\n",
    "targetdata_dir_exp = create_directory(os.path.join(targetdata_dir, \"experiments\"))\n",
    "# # ReaderWriter.dump_data(dpartitions, os.path.join(targetdata_dir, 'data_partitions.pkl'))\n",
    "print(targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.28 s, total: 2.28 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make sure to first run the \"DDoS_Dataset_Generation\" notebook first\n",
    "\n",
    "dataset = MoleculeDataset(root=targetdata_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print()\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('====================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data0 = dataset[0]  # Get the first graph object.\n",
    "# data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_dataset = dataset\n",
    "\n",
    "# If you want to use a smaller subset of the dataset for testing\n",
    "# smaller_dataset_len = int(len(dataset)/1)\n",
    "# used_dataset = dataset[:smaller_dataset_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(used_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_num: 0\n",
      "train data\n",
      "class: 0 norm count: 0.6809885834229253\n",
      "class: 1 norm count: 0.3190114165770747\n",
      "validation data\n",
      "class: 0 norm count: 0.6809490900714121\n",
      "class: 1 norm count: 0.31905090992858787\n",
      "test data\n",
      "class: 0 norm count: 0.6809804644305197\n",
      "class: 1 norm count: 0.31901953556948026\n",
      "\n",
      "-------------------------\n",
      "fold_num: 1\n",
      "train data\n",
      "class: 0 norm count: 0.6809885834229253\n",
      "class: 1 norm count: 0.3190114165770747\n",
      "validation data\n",
      "class: 0 norm count: 0.6809490900714121\n",
      "class: 1 norm count: 0.31905090992858787\n",
      "test data\n",
      "class: 0 norm count: 0.6809804644305197\n",
      "class: 1 norm count: 0.31901953556948026\n",
      "\n",
      "-------------------------\n",
      "fold_num: 2\n",
      "train data\n",
      "class: 0 norm count: 0.6809885834229253\n",
      "class: 1 norm count: 0.3190114165770747\n",
      "validation data\n",
      "class: 0 norm count: 0.6809490900714121\n",
      "class: 1 norm count: 0.31905090992858787\n",
      "test data\n",
      "class: 0 norm count: 0.6809804644305197\n",
      "class: 1 norm count: 0.31901953556948026\n",
      "\n",
      "-------------------------\n",
      "fold_num: 3\n",
      "train data\n",
      "class: 0 norm count: 0.6809798676615515\n",
      "class: 1 norm count: 0.31902013233844856\n",
      "validation data\n",
      "class: 0 norm count: 0.6809490900714121\n",
      "class: 1 norm count: 0.31905090992858787\n",
      "test data\n",
      "class: 0 norm count: 0.6810118416808736\n",
      "class: 1 norm count: 0.3189881583191264\n",
      "\n",
      "-------------------------\n",
      "fold_num: 4\n",
      "train data\n",
      "class: 0 norm count: 0.6809926663509657\n",
      "class: 1 norm count: 0.31900733364903433\n",
      "validation data\n",
      "class: 0 norm count: 0.6809490900714121\n",
      "class: 1 norm count: 0.31905090992858787\n",
      "test data\n",
      "class: 0 norm count: 0.6809657651015989\n",
      "class: 1 norm count: 0.31903423489840116\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "fold_partitions = get_stratified_partitions(dataset.data.y,\n",
    "                                            num_folds=5,\n",
    "                                            valid_set_portion=0.1,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 78132\n",
      "Number of validation graphs: 8682\n",
      "Number of testing graphs: 21704\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training graphs: \"+ str(len(fold_partitions[0]['train'])))\n",
    "print(\"Number of validation graphs: \"+ str(len(fold_partitions[0]['validation'])))\n",
    "print(\"Number of testing graphs: \"+ str(len(fold_partitions[0]['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params total_thresh 4\n",
    "tp = {\n",
    "    \"batch_size\" : 300,\n",
    "    \"num_epochs\" : 100,\n",
    "    \n",
    "    \"emb_dim\" : 100,\n",
    "    \"gnn_type\" : \"gat\",\n",
    "    \"num_layer\" : 5,\n",
    "    \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "    \"input_embed_dim\" : None,\n",
    "    \"gene_embed_dim\": 1,\n",
    "    \"num_attn_heads\" : 2,\n",
    "    \"num_transformer_units\" : 1,\n",
    "    \"p_dropout\" : 0.3,\n",
    "#     \"nonlin_func\" : nn.ReLU(),\n",
    "    \"mlp_embed_factor\" : 2,\n",
    "    \"pooling_mode\" : 'attn',\n",
    "    \"dist_opt\" : 'cosine',\n",
    "\n",
    "    \"base_lr\" : 3e-4, #3e-4\n",
    "    \"max_lr_mul\": 10,\n",
    "    \"l2_reg\" : 1e-7,\n",
    "    \"loss_w\" : 1.,\n",
    "    \"margin_v\" : 1.,\n",
    "\n",
    "    \"expression_dim\" : 64,\n",
    "    \"expression_input_size\" : 908,\n",
    "    \"exp_H1\" : 1024,\n",
    "    \"exp_H2\" : 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = {\n",
    "#     \"batch_size\" : 32,\n",
    "#     \"num_epochs\" : 100,\n",
    "    \n",
    "#     \"emb_dim\" : 100,\n",
    "#     \"gnn_type\" : \"gcn\",\n",
    "#     \"num_layer\" : 5,\n",
    "#     \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "#     \"input_embed_dim\" : None,\n",
    "#     \"gene_embed_dim\": 20,\n",
    "#     \"num_attn_heads\" : 2,\n",
    "#     \"num_transformer_units\" : 1,\n",
    "#     \"p_dropout\" : 0.3,\n",
    "# #     \"nonlin_func\" : nn.ReLU(),\n",
    "#     \"mlp_embed_factor\" : 2,\n",
    "#     \"pooling_mode\" : 'attn',\n",
    "#     \"dist_opt\" : 'cosine',\n",
    "\n",
    "#     \"base_lr\" : 3e-4, #3e-4\n",
    "#     \"max_lr_mul\": 10,\n",
    "#     \"l2_reg\" : 1e-7,\n",
    "#     \"loss_w\" : 1.,\n",
    "#     \"margin_v\" : 1.,\n",
    "\n",
    "#     \"expression_dim\" : 64,\n",
    "#     \"expression_input_size\" : 908,\n",
    "#     \"exp_H1\" : 4096,\n",
    "#     \"exp_H2\" : 1024\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training params total_thresh 3\n",
    "# tp = {\n",
    "#     \"batch_size\" : 300,\n",
    "#     \"num_epochs\" : 200,\n",
    "    \n",
    "#     \"emb_dim\" : 300,\n",
    "#     \"gnn_type\" : \"gatv2\",\n",
    "#     \"num_layer\" : 5,\n",
    "#     \"graph_pooling\" : \"mean\", #attention\n",
    "    \n",
    "#     \"input_embed_dim\" : None,\n",
    "#     \"gene_embed_dim\": 1,\n",
    "#     \"num_attn_heads\" : 2,\n",
    "#     \"num_transformer_units\" : 1,\n",
    "#     \"p_dropout\" : 0.3,\n",
    "# #     \"nonlin_func\" : nn.ReLU(),\n",
    "#     \"mlp_embed_factor\" : 2,\n",
    "#     \"pooling_mode\" : 'attn',\n",
    "#     \"dist_opt\" : 'cosine',\n",
    "\n",
    "#     \"base_lr\" : 3e-5, #3e-4\n",
    "#     \"max_lr_mul\": 10,\n",
    "#     \"l2_reg\" : 1e-8,\n",
    "#     \"loss_w\" : 0.3,\n",
    "#     \"margin_v\" : 1.,\n",
    "\n",
    "#     \"expression_dim\" : 64,\n",
    "#     \"expression_input_size\" : 908,\n",
    "#     \"exp_H1\" : 500,\n",
    "#     \"exp_H2\" : 400\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_q_process(q_process):\n",
    "    print(\">>> spawning hyperparam search process\")\n",
    "    q_process.start()\n",
    "    \n",
    "def join_q_process(q_process):\n",
    "    q_process.join()\n",
    "    print(\"<<< joined hyperparam search process\")\n",
    "    \n",
    "def create_q_process(queue, used_dataset, gpu_num, tphp, exp_dir, partition):\n",
    "#     fold_gpu_map = {0:gpu_num}\n",
    "    return mp.Process(target=deepadr.hyphelperv2VanillaGNN.run_exp_vanilla, args=(queue, used_dataset, gpu_num, tphp, exp_dir, partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "queue = mp.Queue()\n",
    "q_processes = []\n",
    "\n",
    "# partition = fold_partitions[0]\n",
    "time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "print(\"Start: \" + time_stamp)\n",
    "\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "#     device_gpu = get_device(True, index=q_i)\n",
    "    partition = fold_partitions[q_i]\n",
    "    exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"fold_\"+str(q_i)+\"_\"+time_stamp))\n",
    "    create_directory(os.path.join(exp_dir, \"predictions\"))\n",
    "\n",
    "#     tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "    \n",
    "    q_process = create_q_process(queue, dataset, q_i, tp, exp_dir, partition)\n",
    "    q_processes.append(q_process)\n",
    "    spawn_q_process(q_process)\n",
    "\n",
    "spawned_processes = n_gpu\n",
    "    \n",
    "# for q_i in range(len(hyperparam_space)):\n",
    "for q_i in range(min(n_gpu, len(fold_partitions))):\n",
    "    join_q_process(q_processes[q_i])\n",
    "    released_gpu_num = queue.get()\n",
    "    print(\"released_gpu_num:\", released_gpu_num)\n",
    "#     if(spawned_processes < len(hyperparam_space)):\n",
    "# #         device_gpu = get_device(True, index=q_i)\n",
    "#         time_stamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#         exp_dir = create_directory(os.path.join(targetdata_dir_exp, \"exp_\"+str(q_i)+\"_\"+time_stamp))\n",
    "#         tphp = generate_tp_hp(tp, hyperparam_space[q_i], hp_names)\n",
    "\n",
    "#         q_process = create_q_process(queue, used_dataset, released_gpu_num, tphp, exp_dir, partition)\n",
    "#         q_processes.append(q_process)\n",
    "#         spawn_q_process(q_process)\n",
    "#         spawned_processes = spawned_processes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2022-08-19_00-13-46\n"
     ]
    }
   ],
   "source": [
    "print(\"End: \" + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
